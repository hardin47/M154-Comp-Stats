---
title: "Simulating: scenarios, datasets, random variables"
author: "Jo Hardin"
date: "September 21 & 23, 2021"
output:
  xaringan::moon_reader:
    nature:
      highlightlines: true
      titleSlideClass: ["right", "top", "my-title"]
---

```{r echo=FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(broom)
library(knitr)
library(flair)
library(ggthemes)
opts_chunk$set(
  message=FALSE,
  warning=FALSE,
  size='small',
  tidy=FALSE
  )
options(digits=3)

```

```{r echo = FALSE}
#devtools::install_github("gadenbuie/xaringanExtra")
library(xaringanExtra)
xaringanExtra::use_panelset()
```

# Agenda  9/21/21

1. Why simulate?
2. What makes a good simulation?
3. Examples

---

##  What can simulation tell us?

* 2016:  10 of the 16 Republican presidential candidates were allowed into the first debate using an average of the five most recent major national polls.

```{r out.width = '100%', fig.align='center', echo=FALSE}
knitr::include_graphics("../images/GOPdebate.jpg")
```

Simulating who would be in the [first GOP debate](http://www.nytimes.com/interactive/2015/07/21/upshot/election-2015-the-first-gop-debate-and-the-role-of-chance.html) 

---

### Goals of Simulating Complicated Models

The goal of simulating a complicated model is not only to create a program which will provide the desired results.  We also hope to be able to write code such that:

1. The problem is broken down into small pieces.
2. The problem has checks in it to see what works (run the lines *inside* the functions!).
3. uses simple code (as often as possible).

---



## Aside: a few R functions (`ifelse()`)
```{r}
data.frame(value = c(-2:2)) %>%
  mutate(abs_value = ifelse(value >=0, value, -value))  # abs val
```

---

## Aside: a few R functions (`case_when()`)
```{r}
set.seed(4747)
diamonds %>% select(carat, cut, color, price) %>%
  sample_n(20) %>%
  mutate(price_cat = case_when(
    price > 10000 ~ "expensive",
    price > 1500 ~ "medium", 
    TRUE ~ "inexpensive"))
```


---

## Aside: a few R functions (`sample()`)

*sampling*, *shuffling*,  and *resampling*: `sample()` 

```{r}
alph <- letters[1:10]

sample(alph, 5, replace = FALSE) # sample (from a population)

sample(alph, 15, replace = TRUE) # sample (from a population)

sample(alph, 10, replace = FALSE)  # shuffle

sample(alph, 10, replace = TRUE)  # resample
```

---

## Why?

Three simulating methods are used for different purposes:

1. Monte Carlo methods - use *sampling* repeated sampling from populations with known (either via data or via populations) characteristics.


2. Randomization / Permutation methods - use *shuffling* (sampling without replacement) to test hypotheses of "no effect".


3. Bootstrap methods - use *resampling* (sampling with replacement) to establish confidence intervals.

---

## Aside: a few R functions (`set.seed()`)

What if we want to be able to generate the **same** random numbers (here on the interval from 0 to 1) over and over?

```{r}
set.seed(4747)
runif(4, 0, 1) # random uniform numbers

set.seed(123)
runif(4, 0, 1) # random uniform numbers

set.seed(4747)
runif(4, 0, 1) # random uniform numbers
```

---

## Aside: a few R functions (`rep()`, `seq()`)

Output is a vector; `rep ()`has repeated values, `seq()` for a sequence.
```{r}
rep(c("a", "b", "c"), times = 2)

rep(c("a", "b", "c"), times = 1:3)

rep(c("a", "b", "c"), each = 2)

seq(2, 9, by = pi)

seq(47, 40, by = -4)
```


---

```{r eval = FALSE, include = FALSE, echo = FALSE}
## Aside: a few R functions (and/or)
    #```{r}
diamonds %>% 
  select(carat, cut, color, clarity, price) %>% 
  head(3)
    # ```

  # ```{r}
(diamonds$color == "E" & diamonds$cut == "Premium") %>% head()

(diamonds$color == "E" | diamonds$cut == "Premium") %>% head()
  #```


## Aside: a few R functions (and/or)
   #```{r}
diamonds %>% 
  select(carat, cut, color, clarity, price) %>% 
  head(3)
  #```

   #```{r}
# first element ONLY
(diamonds$color == "E" && diamonds$cut == "Premium") 

# first element ONLY
(diamonds$color == "E" || diamonds$cut == "Premium") 
   #```
```




## Small simulation problem

Estimate $E(X)$ where $X=\max \{ k: \sum_{i=1}^k U_i < 1 \}$ and $U_i$ are uniform(0,1).

--

```{r}
sum_unif <- function(.x){
  sumU <- 0
  k <- 0
  while(sumU < 1) {
    sumU <- sumU + runif(1)
    k <- k+1
}
  return(c(k-1, sumU))
}

set.seed(4747)
sum_unif()
```
---

## **purrr** for functional programming

.pull-left[
Recall the `map` functions which are *named* by the **output** the produce.  For example: 

* `map(.x, .f)` is the main mapping function and returns a list

* `map_df(.x, .f)` returns a data frame

* `map_dbl(.x, .f)` returns a numeric (double) vector

* `map_chr(.x, .f)` returns a character vector

* `map_lgl(.x, .f)` returns a logical vector
]

.pull-right[
```{r out.width = '90%', fig.align='center', echo=FALSE, fig.cap = "From Advanced R by Wickham. https://adv-r.hadley.nz/functionals.html"}
knitr::include_graphics("../images/purrr_map.png")
```
]


The first argument is the data object and the second object is the function to iteratively apply.

---

## Small simulation problem

Estimate $E(X)$ where $X=\max \{ k: \sum_{i=1}^k U_i < 1 \}$ and $U_i$ are uniform(0,1).

```{r echo = FALSE, include = FALSE, eval = FALSE}
set.seed(4747)
allk <- c()
for(i in 1:1000){
  k <- 0; sumU <- 0  
  while(sumU < 1) {
    sumU <- sumU + runif(1)
    k <- k+1 }
  allk <- c(allk, k-1) }
mean(allk)
```


To understand the simulation process, the lines of code below should be run one at a time.  We will do that in class, but if you are reviewing these slides, please do it on your own at home.  You should be able to reproduce exactly the results using the example.

.panelset[

.panel[.panel-name[sum function]
```{r}
sum_unif <- function(.x){
  sumU <- 0
  k <- 0
  while(sumU < 1) {
    sumU <- sumU + runif(1)
    k <- k+1
}
  return(c(k-1, sumU))
}
```
]
.panel[.panel-name[mapping]
```{r}
set.seed(4747)
reps <- 1000
 
sim_k_max <- data.frame(row_id = seq(1, reps, 1)) %>%
  mutate(max_for_EX = map(row_id, sum_unif)) %>%
  unnest(max_for_EX) %>%
  mutate(output = rep(c("k", "sum"), reps)) %>%
  pivot_wider(id_cols = row_id, names_from = output, 
              values_from = max_for_EX) 
```
]

.panel[.panel-name[output]
```{r}
sim_k_max
```
]

.panel[.panel-name[expected value]
```{r}
sim_k_max %>%
  summarize(EX = mean(k))
```
]

]

---


## Thoughts on simulating

* break down the problem into **small** steps
* check to see what works
* simple is better

---


## Pass the Pigs
A game by Winning Moves (previously Hasboro) involving rolling pigs

```{r out.width = '100%', fig.align='center', echo=FALSE}
knitr::include_graphics("../images/Pass the Pigs Points.png")
```

---

## Pig Rules

- Roll pigs, accumulate points
- Stop if you want or if you Pig Out (no Oinker)
- First player to 100 points wins

What is your best strategy for winning???

---

## Basic Blackjack

* Card game, goal: sum cards as close to 21 without going over
* A few nuances to card value (e.g., Ace can be 1 or 11)
* Start with 2 cards, build up one card at a time
* Lots of different strategies (also based on dealer's cards)


```{r out.width = '100%', fig.align='center', echo=FALSE}
knitr::include_graphics("../images/Blackjack_game_1.png")
```

---

## What do we need to simulate poker?

> - set-up of cards, dealing, hands
> - "score" (both sum of cards and payout)
> - strategies
> - result of strategies (summary of outcomes)


.footnote[Example and code come from **Data Science in R: a case studies approach to computational reasoning and problem solving** by Nolan and Temple Lang, chapter 9 *Simulating Blackjack* by Hadley Wickham. R code online at [http://rdatasciencecases.org/](http://rdatasciencecases.org/).]


---

## Setting up the Game in R

```{r}
deck = rep(c(1:10, 10, 10, 10), 4)

shuffle_decks = function(ndecks){sample(rep(deck, ndecks))}

head(shuffle_decks(4), 10)
```

---

## Outcome of cards in hand
```{r}
handValue = function(cards) {
  value = sum(cards)
  value
       # Check for an Ace and change value if it doesn't bust
  if (any(cards == 1) && value <= 11) 
    value = value + 10
  
       # Check bust (set to 0); check Blackjack (set to 21.5)
  if(value > 21)  
    0 
  else if (value == 21 && length(cards) == 2)  
    21.5 # Blackjack
  else 
    value
}
handValue(c(10,4))
```

---

## $ of cards in hand
```{r}
winnings = function(dealer, players) {
  if (dealer > 21) {  # Dealer=Blackjack, ties players with Blackjack
    -1 * (players <= 21)
  } else if (dealer == 0) { # Dealer busts - all non-busted players win
    1.5 * (players > 21) +
      1 * (players <= 21 & players > 0) +
     -1 * (players == 0) 
  } else {            # Dealer 21 or below, all players > dealer win
    1.5 * (players > 21) +  
      1 * (players <= 21 & players > dealer) +
     -1 * (players <= 21 & players < dealer) 
  }
}
winnings(17,c(20, 21.5, 14, 0, 21))
```

---

## Better $ of cards in hand
```{r}
winnings = function(dealer, players){
  (players > dealer & players > 21) * 1.5 + # Blackjack
  (players > dealer & players <= 21) * 1 +  # win
  (players < dealer | players == 0) * -1    # lose
}

winnings(17,c(20, 21.5, 14, 0, 21))
winnings(21.5,c(20, 21.5, 14, 0, 21))
```

---

## How well does `handValue` work?
```{r}
test_cards = list( c(10, 1), c(10, 5, 6), c(10, 1, 1), 
                   c(7, 6, 1, 5), c(3, 6, 1, 1), 
                   c(2, 3, 4, 10), c(5, 1, 9, 1, 1),
                   c(5, 10, 7), c(10, 9, 1, 1, 1)) 

test_cards_val = c(21.5, 21, 12, 19, 21, 19, 17, 0, 0)
sapply(test_cards, handValue)  # apply the function handValue to test_cards

identical(test_cards_val, sapply(test_cards, handValue))
```


```{r eval = FALSE, include = FALSE}
## Testing winnings (create known)
test_vals = c(0, 16, 19, 20, 21, 21.5)

testWinnings =
  matrix(c( -1,  1,  1,  1,  1, 1.5,
            -1,  0,  1,  1,  1, 1.5,
            -1, -1,  0,  1,  1, 1.5,
            -1, -1, -1,  0,  1, 1.5,
            -1, -1, -1, -1,  0, 1.5,
            -1, -1, -1, -1, -1, 0), 
         nrow = length(test_vals), byrow = TRUE)
dimnames(testWinnings) = list(dealer = test_vals, 
                              player = test_vals)

testWinnings
```


```{r eval = FALSE, include = FALSE}
## Does `winnings` work?

check = testWinnings  # make the matrix the right size
check[] = NA  # make all entries NA
 
for(i in seq_along(test_vals)) {
  for(j in seq_along(test_vals)) {
    check[i, j] = winnings(test_vals[i], test_vals[j])
  }
}

identical(check, testWinnings)
```

---

## Function for getting more cards 
```{r}
shoe = function(m = 1) sample(deck, m, replace = TRUE)

new_hand = function(shoe, cards = shoe(2), bet = 1) {
  list(bet = bet, shoe = shoe, cards = cards)
}
myCards = new_hand(shoe, bet = 7)
myCards
```

---

## First action: hit
receive another card
```{r}
hit = function(hand) {
  hand$cards = c(hand$cards, hand$shoe(1))
  hand
}

hit(myCards)$cards
```

---

## Second action: stand 
stay with current cards
```{r}
stand = function(hand) hand

stand(myCards)$cards
```

---

## Third action: double down
double the bet after receiving exactly one more card
```{r}
dd =  function(hand) {
  hand$bet = hand$bet * 2
  hand = hit(hand)
  stand(hand)
}

dd(myCards)$cards
```

---

## Fourth action: split a pair
create two different hands from initial hand with two cards of the same value

```{r}
splitPair = function(hand) {
  list( new_hand(hand$shoe, 
             cards = c(hand$cards[1], hand$shoe(1)),
             bet = hand$bet),
        new_hand(hand$shoe, 
             cards = c(hand$cards[2], hand$shoe(1)),
             bet = hand$bet))   }
splitHand = splitPair(myCards)
```


---


## Results of splitting
(can we always split?)
```{r}
splitHand[[1]]$cards
splitHand[[2]]$cards
```

---

## Let's play!  Not yet automated...
```{r}
set.seed(470); dealer = new_hand(shoe); player = new_hand(shoe); 
dealer$cards[1]
player$cards; player = hit(player); player$cards
dealer$cards; dealer = hit(dealer); dealer$cards
```

---

## Who won?
```{r}
dealer$cards; player$cards
handValue(dealer$cards); handValue(player$cards)
winnings(handValue(dealer$cards), handValue(player$cards))
```

---

##  Simply strategy
recall the handValue function -- what if player busts?
```{r}
strategy_simple = function(mine, dealerFaceUp) {
  if (handValue(dealerFaceUp) > 6 && handValue(mine) < 17) 
     "H" 
  else 
     "S"
}
```

---

## Better simple strategy
```{r}
strategy_simple = function(mine, dealerFaceUp) {
  if (handValue(mine) == 0) return("S")
  if (handValue(dealerFaceUp) > 6 && handValue(mine) < 17) 
     "H" 
  else 
     "S"
}
```

---

##  Dealer
The dealer gets cards regardless of what the player does
```{r}
dealer_cards = function(shoe) {
  cards = shoe(2)
  while(handValue(cards) < 17 && handValue(cards) > 0) {
    cards = c(cards, shoe(1))
  }
  cards
}

dealer_cards(shoe)
dealer_cards(shoe)
```

---

## Playing a hand
```{r}
play_hand = function(shoe, strategy, 
                      hand = new_hand(shoe), 
                      dealer = dealer_cards(shoe)) {
  
  face_up_card = dealer[1]
  
  action = strategy(hand$cards, face_up_card)
  while(action != "S" && handValue(hand$cards) != 0) {
    if (action == "H") {
      hand = hit(hand)
      action = strategy(hand$cards, face_up_card)
    } else {
      stop("Unknown action: should be one of S, H")
    }
  }  

  winnings(handValue(dealer), handValue(hand$cards)) * hand$bet
}
```

---

## Play a few hands
```{r}
play_hand(shoe, strategy_simple)

play_hand(shoe, strategy_simple)

play_hand(shoe, strategy_simple, new_hand(shoe, bet=7))

play_hand(shoe, strategy_simple, new_hand(shoe, bet=7))
```

---

## Repeated games

To repeat the game, we simply repeat the `play_hand` function and keep track of the dollars gained or lost.

```{r}
set.seed(4747)
reps <- 10
money <- 20

map_dbl(1:reps, ~ play_hand(shoe, strategy_simple)) %>%
  accumulate(`+`) + 20
```


```{r eval = FALSE, include = FALSE}
play_hand_2 <- function(.x, shoe, strategy, 
                      hand = new_hand(shoe), 
                      dealer = dealer_cards(shoe)) {
  
  face_up_card <- dealer[1]
  
  action <- strategy(hand$cards, face_up_card)
  while(action != "S" && handValue(hand$cards) != 0) {
    if (action == "H") {
      hand = hit(hand)
      action = strategy(hand$cards, face_up_card)
    } else {
      stop("Unknown action: should be one of S, H")
    }
  }  

  winnings(handValue(dealer), handValue(hand$cards)) * hand$bet
}

play_hand_2()
```


```{r eval = FALSE, include = FALSE}
## Generating U[0,1] variables
 a=31541435235; b=23462146143; m=423514351351

xval=47; reps=10000; unif.val = c()

for(i in 1:reps){   xval = (a*xval + b) %% m
  unif.val = c(unif.val, xval/m)   }
```


```{r eval = FALSE, include = FALSE}
## Plot of U[0,1] values
data.frame(uniformRVs = unif.val) %>%
  ggplot(aes(x = uniformRVs)) + geom_histogram(bins = 25)
```



```{r eval = FALSE, include = FALSE}
## Generating random Weibull(2,1) variables
unifdata = runif(10000,0,1)
weib1data = sqrt(-log(1-unifdata))
weib2data = rweibull(10000,2,1)

weibdata <- data.frame(weibull = c(weib1data, weib2data),
                       sim.method = c(rep("InvTrans", 10000), 
                                      rep("rweibull", 10000)))

```


```{r eval = FALSE, include = FALSE}
## Plot of Weibull data
ggplot(weibdata, aes(x = weibull)) + geom_histogram(bins = 25) + 
  facet_grid(~sim.method)
```


---

# Agenda  9/23/21

1. Bias in modeling
2. Simulating statistical inference

---

## Bias in a model

```
talent ~ Normal (100, 15)
grades ~ Normal (talent, 15)
SAT ~ Normal (talent, 15)
```

College wants to admit students with 
> `talent > 115` 

... but they only have access to `grades` and `SAT` which are noisy estimates of `talent`.

The example is taken directly (and mostly verbatim) from a blog by Aaron Roth [Algorithmic Unfairness Without Any Bias Baked In](http://aaronsadventures.blogspot.com/2019/01/discussion-of-unfairness-in-machine.html).  

---

## Plan for accepting students

* Run a regression on a training dataset (`talent` is known for existing students)
* Find a model which predicts `talent` based on `grades` and `SAT`
* Choose students for whom predicted `talent` is above 115

---

##  Flaw in the plan ...

* there are two populations of students, the Reds and Blues. 
* Reds are the majority population (99%), and Blues are a small minority population (1%) 
* the Reds and the Blues are no different when it comes to talent: they both have the same talent distribution, as described above. 
* there is no bias baked into the grading or the exams: both the Reds and the Blues also have exactly the same grade and exam score distributions

--

> But there is one difference: the Blues have more money than the Reds, so they each take the **SAT twice**, and report only the highest of the two scores to the college. This results in a small but noticeable bump in their average SAT scores, compared to the Reds.

---

##  Key aspect:

> The value of `SAT` means something different for the Reds versus the Blues

(They have different feature distributions.)

---

##  Let's see what happens ...

```{r echo=FALSE}
set.seed(470)
n = 100000
n.red = n*0.99
n.blue = n*0.01
reds <- rnorm(n.red, mean = 100, sd = 15)
blues <- rnorm(n.blue, mean = 100, sd = 15)

red.sat <- reds + rnorm(n.red, mean = 0, sd = 15)
blue.sat <- blues + 
    pmax(rnorm(n.blue, mean = 0, sd = 15),
         rnorm(n.blue, mean = 0, sd = 15))

red.grade <- reds + rnorm(n.red, mean = 0, sd = 15)
blue.grade <- blues + rnorm(n.blue, mean = 0, sd = 15)

college.data <- data.frame(talent = c(reds, blues),
                           SAT = c(red.sat, blue.sat),
                           grades = c(red.grade, blue.grade),
                           color = c(rep("red", n.red), rep("blue", n.blue)))

ggplot(college.data, aes(x = grades, y = SAT, color = color)) +
  geom_point(size = 0.5) +
  scale_color_identity(name = "Color Group",
                       guide = "legend") +
  geom_abline(intercept = 0, slope = 1)
  
```

---

## Two models:

```{r echo = FALSE}
red.lm = college.data %>%
  dplyr::filter(color == "red") %>%
  lm(talent ~ SAT + grades, data = .)

blue.lm = college.data %>%
  dplyr::filter(color == "blue") %>%
  lm(talent ~ SAT + grades, data = .)
```

Red model (SAT taken once):
```{r echo = FALSE}
red.lm %>% broom::tidy()
```
Blue model (SAT is max score of two):
```{r echo = FALSE}
blue.lm %>% broom::tidy()
```

---

## New data

* Generate new data and use the **two** models above, separately. 

* How well do the models predict if a student has `talent` > 115?

```{r echo=FALSE}
set.seed(470)
new.reds <- rnorm(n.red, mean = 100, sd = 15)
new.blues <- rnorm(n.blue, mean = 100, sd = 15)

new.red.sat <- new.reds + rnorm(n.red, mean = 0, sd = 15)
new.blue.sat <- new.blues + 
    pmax(rnorm(n.blue, mean = 0, sd = 15),
         rnorm(n.blue, mean = 0, sd = 15))

new.red.grade <- new.reds + rnorm(n.red, mean = 0, sd = 15)
new.blue.grade <- new.blues + rnorm(n.blue, mean = 0, sd = 15)

new.college.data <- data.frame(talent = c(new.reds, new.blues),
                           SAT = c(new.red.sat, new.blue.sat),
                           grades = c(new.red.grade, new.blue.grade),
                           color = c(rep("red", n.red), rep("blue", n.blue)))


new.red.pred <- new.college.data %>%
  filter(color == "red") %>%
  predict.lm(red.lm, newdata = .)

new.blue.pred <- new.college.data %>%
  filter(color == "blue") %>%
  predict.lm(blue.lm, newdata = .)

new.college.data <- new.college.data %>% 
  cbind(predicted = c(new.red.pred, new.blue.pred))

ggplot(new.college.data, aes(x = talent, y = predicted, color = color)) + 
  geom_point(size = 0.5) + 
  geom_hline(yintercept = 115) + 
  geom_vline(xintercept = 115) +
  scale_color_identity(name = "Color Group",
                       guide = "legend")
```

---

## New data

.pull-left[
```{r echo=FALSE}
ggplot(new.college.data, aes(x = talent, y = predicted, color = color)) + 
  geom_point(size = 0.5) + 
  geom_hline(yintercept = 115) + 
  geom_vline(xintercept = 115) +
  scale_color_identity(name = "Color Group",
                       guide = "legend")
```
]


.pull-right[
```{r echo=FALSE}
new.college.data <- new.college.data %>% 
  mutate(fp = ifelse(talent < 115 & predicted > 115, 1, 0),
         tp = ifelse(talent > 115 & predicted > 115, 1, 0),
         fn = ifelse(talent > 115 & predicted < 115, 1, 0),
         tn = ifelse(talent < 115 & predicted < 115, 1, 0))

error.rates <- new.college.data %>% group_by(color) %>%
  summarize(tpr = sum(tp) / (sum(tp) + sum(fn)),
            fpr = sum(fp) / (sum(fp) + sum(tn)),
            fnr = sum(fn) / (sum(fn) + sum(tp)),
            #fdr = sum(fp) / (sum(fp) + sum(tp)),
            error = (sum(fp) + sum(fn)) / (sum(fp) + sum(tp) + sum(fn) + sum(tn) ))

error.rates
```

]

---

## **TWO** models doesn't seem right????

What if we fit only one model to the entire dataset?

Afterall, there are laws against using protected classes to make decisions (housing, jobs, money loans, college, etc.)

```{r echo = FALSE}
global.lm = college.data %>%
  lm(talent ~ SAT + grades, data = .)

global.lm %>% broom::tidy()
```

(The coefficients kinda look like the red model...)
---

## How do the error rates change?

.pull-left[
```{r echo=FALSE}
new.pred <- new.college.data %>%
  predict.lm(global.lm, newdata = .)

new.college.data <- new.college.data %>% 
  cbind(global.predicted = new.pred)

ggplot(new.college.data, aes(x = talent, 
                             y = global.predicted, 
                             color = color)) + 
  geom_point(size = 0.5) + 
  geom_hline(yintercept = 115) + 
  geom_vline(xintercept = 115) +
  scale_color_identity(name = "Color Group",
                       guide = "legend")
```
]

.pull-right[

One model:
```{r echo = FALSE}
new.college.data.glb <- new.college.data %>% 
  mutate(fp = ifelse(talent < 115 & global.predicted > 115, 1, 0),
         tp = ifelse(talent > 115 & global.predicted > 115, 1, 0),
         fn = ifelse(talent > 115 & global.predicted < 115, 1, 0),
         tn = ifelse(talent < 115 & global.predicted < 115, 1, 0))

error.rates <- new.college.data.glb %>% group_by(color) %>%
  summarize(tpr = sum(tp) / (sum(tp) + sum(fn)),
            fpr = sum(fp) / (sum(fp) + sum(tn)),
            fnr = sum(fn) / (sum(fn) + sum(tp)),
            #fdr = sum(fp) / (sum(fp) + sum(tp)),
            error = (sum(fp) + sum(fn)) / (sum(fp) + sum(tp) + sum(fn) + sum(tn) ))

error.rates
```

Two separate models:
```{r echo = FALSE}
new.college.data.2mod <- new.college.data %>% 
  mutate(fp = ifelse(talent < 115 & predicted > 115, 1, 0),
         tp = ifelse(talent > 115 & predicted > 115, 1, 0),
         fn = ifelse(talent > 115 & predicted < 115, 1, 0),
         tn = ifelse(talent < 115 & predicted < 115, 1, 0))

error.rates <- new.college.data.2mod %>% group_by(color) %>%
  summarize(tpr = sum(tp) / (sum(tp) + sum(fn)),
            fpr = sum(fp) / (sum(fp) + sum(tn)),
            fnr = sum(fn) / (sum(fn) + sum(tp)),
            #fdr = sum(fp) / (sum(fp) + sum(tp)),
            error = (sum(fp) + sum(fn)) / (sum(fp) + sum(tp) + sum(fn) + sum(tn) ))

error.rates
```


]
---

##  What did we learn?

> with two populations that have different feature distributions, learning a single classifier (that is prohibited from discriminating based on population) will fit the bigger of the two populations

* depending on the nature of the distribution difference, it can be either to the benefit or the detriment of the minority population

* no explicit human bias, either on the part of the algorithm designer or the data gathering process

* the problem is exacerbated if we artificially force the algorithm to be group blind

* well intentioned "fairness" regulations prohibiting decision makers form taking sensitive attributes into account can actually make things less fair and less accurate at the same time

---

## Simulate?

* different varying proportions
* effect due to variability
* effect due to SAT coefficient
* different number of times the blues get to take the test
* etc.

---

## Sensitivity of CI to tech conditions

Consider the following set up (as in the WU):

```{r echo=FALSE}
library(ggplot2)
library(ggthemes)
library(broom)
```

```{r}
set.seed(4747)
beta0 <- -1; beta1 <- 0.5; beta2 <- 1.5
n_obs <- 100; reps <- 1000


  x1 <- rep(c(0,1), each=n_obs/2)
  x2 <- runif(n_obs, min=-1, max=1)
  y <- beta0 + beta1*x1 + beta2*x2 + rnorm(n_obs, mean=0, sd = 1)
```

---

## Plot of data
```{r echo = FALSE}
data.frame(x1value = as.factor(x1),x2value = x2,yvalue = y) %>%
  ggplot(aes(x=x2value, y = yvalue, color=x1value)) + 
  geom_point() +
  geom_smooth(method = "lm", se=FALSE) + 
  scale_colour_tableau("Color Blind") +
  guides(color=guide_legend(title="group"))
```


---

## Capture the slope parameter?

* We know the truth (!!!!!)
* We can create a CI for the parameter given the data set
* Is the parameter in the interval?
* Should it always be in the interval?  How often?


See: [Rossman Chance regression applet](https://www.rossmanchance.com/applets/2021/regshuffle/regshuffle.htm)

---

## Running a linear model

```{r}
CI <- lm(y~x1+x2) %>% tidy(conf.int=TRUE) %>% data.frame()
CI

CI %>%
  filter(term == "x2") %>%
  select(term, estimate, conf.low, conf.high) %>%
  mutate(inside = between(beta2, conf.low, conf.high))
```

---

## What happens to the CI of coefficients in repeated samples? (eq var)
```{r}
eqvar_data <- data.frame(row_id = seq(1, n_obs, 1)) %>%
  slice(rep(row_id, each = reps)) %>%
  mutate(
    sim_id = rep(1:reps, n_obs),
    x1 = rep(c(0,1), each = n()/2),
    x2 = runif(n(), min = -1, max = 1),
    y = beta0 + beta1*x1 + beta2*x2 + rnorm(n(), mean = 0, sd = 1)
  ) %>%
  arrange(sim_id, row_id) %>%
  group_by(sim_id) %>%
  nest()

eqvar_data
``` 

---

```{r}
beta_coef <- function(df){
  lm(y ~ x1 + x2, data = df) %>%
    tidy(conf.int = TRUE) %>%
    filter(term == "x2") %>%
    select(estimate, conf.low, conf.high, p.value) 
}

eqvar_data %>% 
  mutate(b2_vals = map(data, beta_coef)) %>%
  select(b2_vals) %>% 
  unnest(b2_vals) %>%
  summarize(capture = between(beta2, conf.low, conf.high)) %>%
  summarize(capture_rate = sum(capture)/reps)
```

---

## Sensitivity of CI to tech conditions

Consider the following set up (note the difference in variability):

```{r unequal-ci-1, eval=FALSE, include = FALSE}
set.seed(470)
beta0 <- -1
beta1 <- 0.5
beta2 <- 1.5
n <- 100
reps <- 1000

  x1 <- rep(c(0,1), each=n/2)
  x2 <- runif(n, min=-1, max=1)
  y <- beta0 + beta1*x1 + beta2*x2 + 
             rnorm(n, mean=0, sd = 1 + x1 + 10*abs(x2))
```

```{r echo = FALSE}
decorate("unequal-ci-1", eval = TRUE) %>%
  flair("sd = 1 + x1 + 10*abs(x2)") %>%
  knit_print.with_flair()
```

---

## Plot of data
```{r echo = FALSE}
data.frame(x1value = as.factor(x1),x2value = x2,yvalue = y) %>%
  ggplot(aes(x=x2value, y = yvalue, color=x1value)) + 
  geom_point() +
  geom_smooth(method = "lm", se=FALSE) + 
  scale_colour_tableau("Color Blind") +
  guides(color=guide_legend(title="group"))
```

---

## What happens to the CI of coefficients in repeated samples? (uneq var)
```{r echo = FALSE}
set.seed(47)
```


```{r unequal-ci, eval=FALSE, include = FALSE}
uneqvar_data <- data.frame(row_id = seq(1, n_obs, 1)) %>%
  slice(rep(row_id, each = reps)) %>%
  mutate(sim_id = rep(1:reps, n_obs), 
         x1 = rep(c(0,1), each = n()/2),
         x2 = runif(n(), min = -1, max = 1),
         y = beta0 + beta1*x1 + beta2*x2 + 
              rnorm(n(), mean = 0, sd = 1 + x1 + 10*abs(x2))  ) %>%
  arrange(sim_id, row_id) %>%
  group_by(sim_id) %>% nest() 

uneqvar_data %>% 
  mutate(b2_vals = map(data, beta_coef)) %>%
  select(b2_vals) %>% unnest(b2_vals) %>%
  summarize(capture = between(beta2, conf.low, conf.high)) %>%
  summarize(capture_rate = sum(capture)/reps)
```

```{r echo = FALSE}
decorate("unequal-ci", eval = TRUE) %>%
  flair("sd = 1 + x1 + 10*abs(x2)") %>%
  knit_print.with_flair()
```



---

## All together

.panelset[

.panel[.panel-name[coef function]
```{r}
beta_coef <- function(df){
  lm(y ~ x1 + x2, data = df) %>%
    tidy(conf.int = TRUE) %>%
    filter(term == "x2") %>%
    select(estimate, conf.low, conf.high, p.value) 
}
```
]

.panel[.panel-name[generate data]
```{r echo = FALSE}
set.seed(47)
```
```{r}
uneqvar_data <- 
  data.frame(row_id = seq(1, n_obs, 1)) %>%
  slice(rep(row_id, each = reps)) %>%
  mutate(sim_id = rep(1:reps, n_obs), 
         x1 = rep(c(0,1), each = n()/2),
         x2 = runif(n(), min = -1, max = 1),
         y = beta0 + beta1*x1 + beta2*x2 + 
              rnorm(n(), mean = 0, sd = 1 + x1 + 10*abs(x2))  ) %>%
  arrange(sim_id, row_id) %>%
  group_by(sim_id) %>% 
  nest() 
```
]


.panel[.panel-name[capture rate]
```{r}
uneqvar_data %>% 
  mutate(b2_vals = map(data, beta_coef)) %>%
  select(b2_vals) %>% unnest(b2_vals) %>%
  summarize(capture = between(beta2, conf.low, conf.high)) %>%
  summarize(capture_rate = sum(capture)/reps)
```
]
]

---

## Equal variance: type I error?

We can also consider the type I errors associated with the two data configurations.  With equal variance, the type I error rate is close to what we'd expect, 5%.

.panelset[

.panel[.panel-name[t-test function]
```{r}
t_test_pval <- function(df){
  t.test(y ~ x1, data = df, var.equal = TRUE) %>%
    tidy() %>%
    select(estimate, p.value) 
}
```
]

.panel[.panel-name[generate data]
```{r}
set.seed(470)
reps <- 1000
n_obs <- 20
null_data <- 
  data.frame(row_id = seq(1, n_obs, 1)) %>%
  slice(rep(row_id, each = reps)) %>%
  mutate(
    sim_id = rep(1:reps, n_obs),
    x1 = rep(c("group1", "group2"), each = n()/2),
    y = rnorm(n(), mean = 10, 
               sd = rep(c(1,1), each = n()/2))
  ) %>%
  arrange(sim_id, row_id) %>%
  group_by(sim_id) %>%
  nest()
```
]

.panel[.panel-name[summarize p-values]
```{r}
null_data %>% 
  mutate(t_vals = map(data,t_test_pval)) %>%
  select(t_vals) %>% 
  unnest(t_vals) %>%
  ungroup(sim_id) %>%
  summarize(type1error_rate = sum(p.value < 0.05)/reps)
```
]

]

---

## Unequal variance: type I error?

With unequal variance, the type I error rate is much higher than we set.  We set the the type I error rate to be 5%, but the simulated rate was 6.36%.

.panelset[

.panel[.panel-name[t-test function]
```{r}
t_test_pval <- function(df){
  t.test(y ~ x1, data = df, var.equal = TRUE) %>%
    tidy() %>%
    select(estimate, p.value) 
}
```
]

.panel[.panel-name[generate data]
```{r unequal-ttest, eval = FALSE, include = FALSE}
set.seed(470)
reps <- 1000
n_obs <- 20
null_data <- 
  data.frame(row_id = seq(1, n_obs, 1)) %>%
  slice(rep(row_id, each = reps)) %>%
  mutate(
    sim_id = rep(1:reps, n_obs),
    x1 = rep(c("group1", "group2"), each = n()/2),
    y = rnorm(n(), mean = 10, 
               sd = rep(c(1,100), each = n()/2))
  ) %>%
  arrange(sim_id, row_id) %>%
  group_by(sim_id) %>%
  nest()
```

```{r echo = FALSE}
decorate("unequal-ttest", eval = TRUE) %>%
  flair("sd = rep(c(1,100), each = n()/2)") %>%
  knit_print.with_flair()
```

]

.panel[.panel-name[summarize p-values]
```{r}
null_data %>% 
  mutate(t_vals = map(data,t_test_pval)) %>%
  select(t_vals) %>% 
  unnest(t_vals) %>%
  ungroup(sim_id) %>%
  summarize(type1error_rate = sum(p.value < 0.05)/reps)
```
]

]

