
# Clicker Questions

to go along with <br>

<b><a href = "https://mdsr-book.github.io/mdsr3e/" target = "_blank">Modern Data Science with R, 3rd edition</a></b> by Baumer, Kaplan, and Horton

<b><a href = "https://www.statlearning.com/" target = "_blank">Introduction to Statistical Learning with Applications in R</a></b> by James, Witten, Hastie, and Tibshirani


<!-- the two formats are html and revealjs -->


```{=html}
<style>
.reveal ol ol {
   list-style-type: lower-alpha;
}
</style>
```


```{r}
#| echo: false
#| message: false
#| warning: false

# figure options
knitr::opts_chunk$set(warning = FALSE, message = FALSE,
  fig.width = 10, fig.asp = 0.618, out.width = "90%",
  fig.retina = 3, dpi = 300, fig.align = "center"
)

library(tidyverse)

# Make sure to put a space before and after every slide break "---"

```

---

(@) The reason to take random samples is:[^1]
   (a) to make cause and effect conclusions 
   (b) to get as many variables as possible
   (c) it's easier to collect a large dataset
   (d) so that the data are a good representation of the population
   (e) I have no idea why one would take a random sample

[^1]: d. so that the data are a good representation of the population

---

(@) The reason to allocate/assign explanatory variables is:[^2]
   (a) to make cause and effect conclusions 
   (b) to get as many variables as possible
   (c) it's easier to collect a large dataset
   (d) so that the data are a good representation of the population
   (e) I have no idea what you mean by "allocate/assign" (or "explanatory variable" for that matter)

[^2]: a. to make cause and effect conclusions

---

(@) Approximately how big is a tweet?[^3]  
    (a) 0.01Kb
    (b) 0.1Kb
    (c) 1Kb
    (d) 100Kb
    (e) 1000Kb = 1Mb

[^3]: b. about 0.1Kb.  Turns out that 3.5 billion tweets * 0.1Kb = 350Gb (0.35 Tb).  My laptop is pretty good, and it has 36 Gb of memory (RAM) and 4 Tb of storage.  It would not be able to work with 3.5 billion tweets.

---

(@) $R^2$ measures:[^4]
   (a) the proportion of variability in vote margin as explained by tweet share.
   (b) the proportion of variability in tweet share as explained by vote margin.
   (c) how appropriate the linear part of the linear model is.
   (d) whether or not particular variables should be included in the model.

[^4]: a. the proportion of variability in vote margin as explained by tweet share.

---

(@) R / R Studio / Quarto[^5]
    (a) all good
    (b) started, progress is slow and steady
    (c) started, very stuck
    (d) haven’t started yet
    (e) what do you mean by "R"?

[^5]: wherever you are, make sure you are communicating with me when you have questions!

---

(@) Git / GitHub[^6]
    (a) all good
    (b) started, progress is slow and steady
    (c) started, very stuck
    (d) haven’t started yet
    (e) what do you mean by "Git"?

[^6]: wherever you are, make sure you are communicating with me when you have questions!

---

(@) Which of the following includes talking to the remote version of GitHub?[^7]
    (a) changing your name (updating the YAML)
    (b) committing the file(s)
    (c) pushing the file(s)
    (d) some of the above
    (e) all of the above
    
[^7]: d. pushing the file(s)

---

(@) What is the error?[^8]
    (a) poor assignment operator
    (b) unmatched quotes
    (c) improper syntax for function argument
    (d) invalid object name
    (e) no mistake

```{r}
#| eval: false
#| echo: true
shup2 <-- "Hello to you!"
```

[^8]: a. poor assignment operator

---

(@) What is the error?[^9]
    (a) poor assignment operator
    (b) unmatched quotes
    (c) improper syntax for function argument
    (d) invalid object name
    (e) no mistake

```{r}
#| eval: false
#| echo: true
3shup <-  "Hello to you!"
```

[^9]: d. invalid object name

---

(@) What is the error?[^10]
    (a) poor assignment operator
    (b) unmatched quotes
    (c) improper syntax for function argument
    (d) invalid object name
    (e) no mistake

```{r}
#| eval: false
#| echo: true
shup4 <-  "Hello to you!
```

[^10]: b. unmatched quotes

---

(@) What is the error?[^11]
    (a) poor assignment operator
    (b) unmatched quotes
    (c) improper syntax for function argument
    (d) invalid object name
    (e) no mistake

```{r}
#| eval: false
#| echo: true
shup5 <-  date()
```

[^11]: e. no mistake

---

(@) What is the error?[^12]
    (a) poor assignment operator
    (b) unmatched quotes
    (c) improper syntax for function argument
    (d) invalid object name
    (e) no mistake

```{r}
#| eval: false
#| echo: true
shup6 <-  sqrt 10
```

[^12]: c. improper syntax for a function argument

---

(@) Do you keep a calendar / schedule / planner?[^13]
     (a) Yes
     (b) No
     
[^13]: a. I mean, the right answer has to be Yes, right!??!

---

(@) Do you keep a calendar / schedule / planner?  If you answered "Yes" ...[^14]
     (a)	Yes, on Google Calendar
     (b)	Yes, on Calendar for macOS
     (c)	Yes, on Outlook for Windows
     (d)	Yes, in some other app
     (e)	Yes, by hand


[^14]: no right answer here!

---

(@) Where should I put things I've created for the HW (e.g., data, .ics file, etc.)[^15]
    (a) Upload into remote GitHub directory
    (b) In the local folder which also has the R project
    (c) In my Downloads
    (d) Somewhere on my Desktop
    (e) In my Home directory
    
[^15]: b. In the local folder which also has the R project.  It could be on the Desktop or the Home directory, but it must be in the same place as the R project. Do **not** upload files to the remote GitHub directory or you will find yourself with two different copies of the files.

---

(@) The goal of making a figure is...[^16]
     (a)  To draw attention to your work.
     (b) To facilitate comparisons.
     (c) To provide as much information as possible.

[^16]: Yes! All the responses are reasons to make a figure.

---

(@) A good reason to make a particular choice of a graph is:[^17]
     (a) Because the journal / field has particular expectations for how the data are presented.
     (b) Because some variables naturally fit better on some graphs (e.g., numbers on scatter plots).
     (c) Because that graphic displays the message you want as optimally as possible.

[^17]: c. Because that graphic displays the message you want as optimally as possible.

---

(@) Why are the points orange?[^18]
     (a) R translates "navy" into orange.
     (b) color must be specified in `geom_point()`
     (c) color must be specified **outside** the `aes()` function
     (d) the default plot color is orange
     
:::: {.columns}

::: {.column width="35%"}
```{r}
#| echo: false
library(mosaic)
data(Births78)
ggplot(data = Births78, 
       aes(x = date, y = births, color = "navy")) + 
  geom_point() +          
  labs(title = "US Births in 1978")
```
:::

::: {.column width="65%"}
```{r}
#| eval: false
#| echo: true
ggplot(data = Births78, 
       aes(x = date, y = births, color = "navy")) + 
  geom_point() +          
  labs(title = "US Births in 1978")
```
:::

::::

[^18]: c. color must be specified **outside** the `aes()` function

---

(@) Why are the dots blue and the lines colored?[^19]
     (a) dot color is given as "navy", line color is given as `wday`.
     (b) both colors are specified in the `ggplot()` function.
     (c) dot coloring takes precedence over line coloring.
     (d) line coloring takes precedence over dot coloring.
     
```{r}
#| echo: false
#| out-width: 60%
library(mosaic)
data(Births78)
ggplot(data = Births78, 
       aes(x = date, y = births)) + 
  geom_line(aes(color = wday)) +       
  geom_point(color = "navy") +          
  labs(title = "US Births in 1978")
```
     
[^19]: a. dot color is specified as "navy", line color is specified as `wday`.

---

(@) Setting vs. Mapping.  If I want information to be passed to all data points (not variable):[^20]
     (a) map the information inside the `aes()` function.
     (b) set the information outside the `aes()` function
     
[^20]: b. set the information outside the `aes()` function

---

(@) The Snow figure was most successful at:[^21]
     (a) making the data stand out
     (b) facilitating comparison
     (c) putting the work in context
     (d) simplifying the story

[^21]: answers may vary. I'd say c. putting the work in context.  Others might say b. facilitating comparison or d. simplifying the story.  However, I don't think a correct answer is a. making the data stand out.

---

(@) The Challenger figure(s) was(were) least successful at:[^22]
    (a) making the data stand out
    (b) facilitating comparison
    (c) putting the work in context
    (d) simplifying the story

[^22]: a. making the data stand out

---

(@) The biggest difference between Snow and the Challenger was:[^23]
    (a)	The **amount** of information portrayed.
    (b)	One was better at displaying **cause**.
    (c)	One showed the relevant **comparison** better.
    (d)	One was more **artistic**.

[^23]: c. One showed the relevant **comparison** better.

---
 
(@) Caffeine and Calories.  What was the biggest concern over the average value axes?[^24]
     (a) It isn’t at the origin.
     (b) They should have used all the data possible to find averages.
     (c) There wasn’t a random sample.
     (d) There wasn’t a label explaining why the axes were where they were.
     
[^24]: a. It isn’t at the origin. in combination with d. There wasn’t a label explaining why the axes were where they were.  The story associated with the average value axes is not clear to the reader.

---

(@) What is wrong with the following code?[^25]
    (a) should only  be one =
    (b) Sydney should be lower case
    (c) name should not be in quotes
    (d) use mutate instead of filter
    (e) babynames in wrong place

```{r}
#| eval: false
#| echo: true
Result <- |> filter(babynames,
		name== "Sydney")
```

[^25]: e. babynames in wrong place

---

(@) Which data represents the ideal format for **ggplot2** and **dplyr**?[^26]

```{r}
#| echo: false
tribble_a <- tribble(
  ~year, ~Algeria, ~Brazil, ~Columbia,
  2000, 7, 12, 16,
  2001, 9, 14, 18
)
tribble_a |> gt::gt(caption = "table a") 
```

```{r}
#| echo: false
tribble_b <- tribble(
  ~country, ~Y2000, ~Y2001,
  "Algeria", 7, 9,
  "Brazil", 12, 14,
  "Columbia", 16, 18
)
tribble_b |> gt::gt(caption = "table b") 
```

```{r}
#| echo: false
tribble_c <- tribble(
  ~country, ~year, ~value,
  "Algeria", 2000, 7,
  "Algeria", 2001, 9,
  "Brazil", 2000, 12,
  "Brazil", 2001, 14,
  "Columbia", 2000, 16, 
  "Columbia", 2001, 18
)
tribble_c |> gt::gt(caption = "table c") 
```

[^26]: c. Table c is best because the columns allow us to work with each of the variable separately.

---

(@) Each of the statements except one will accomplish the same calculation.  Which one does not match?[^27]

```{r}
#| eval: false
#| echo: true
#(a) 
babynames |> 
  group_by(year, sex) |> 
  summarize(totalBirths = sum(num))

#(b) 
group_by(babynames, year, sex) |> 
  summarize(totalBirths = sum(num))

#(c)
group_by(babynames, year, sex) |> 
  summarize(totalBirths = mean(num))

#(d)
temp <- group_by(babynames, year, sex)

summarize(temp, totalBirths = sum(num))

#(e)
summarize(group_by(babynames, year, sex), 
          totalBirths = sum(num))
```

[^27]: c. does something different because it takes the `mean()` (average) instead of the `sum()`.  The other commands compute the total number of births broken down by `year` and `sex`.

---

(@) Fill in Q1.[^28]
    (a) `filter()`
    (b) `arrange()`
    (c) `select()`
    (d) `mutate()`
    (e) `group_by()`
    
```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "2,3"
result <- babynames |>
  Q1(name %in% c("Jane", "Mary")) |> 
  # just the Janes and Marys
  group_by(Q2, Q2) |> 
  summarize(total = Q3)
```

[^28]: a. `filter()`

---

(@) Fill in Q2.[^29]
    (a) `(year, sex)`
    (b) `(year, name)`
    (c) `(year, num)`
    (d) `(sex, name)`
    (e) `(sex, num)`
    
```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "3,4"
result <- babynames |>
  Q1(name %in% c("Jane", "Mary")) |> 
  group_by(Q2, Q2) |> 
  # for each year for each name
  summarize(total = Q3)
```

[^29]: b. `(year, name)`

---

(@) Fill in Q3.[^30]
    (a) `n_distinct(name)`
    (b) `n_distinct(n)`
    (c) `sum(name)`
    (d) `sum(num)`
    (e) `mean(num)`

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "4,5"
result <- babynames |>
  Q1(name %in% c("Jane", "Mary")) |> 
  group_by(Q2, Q2) |> 
  summarize(total = Q3)
  # number of babies (each year, each name)
```

[^30]: d. `sum(num)`

---

(@) Running the code.[^31]

```{r}
#| echo: true
babynames <- babynames::babynames |> 
  rename(num = n)

babynames |>
  filter(name %in% c("Jane", "Mary")) |> 
  # just the Janes and Marys
  group_by(name, year) |> 
  # for each year for each name
  summarize(total = sum(num))
```


```{r}
#| error: true
#| echo: true

babynames |>
  filter(name %in% c("Jane", "Mary")) |> 
  group_by(name, year) |> 
  summarize(number = sum(num))

babynames |>
  filter(name %in% c("Jane", "Mary")) |> 
  group_by(name, year) |> 
  summarize(n_distinct(name))

babynames |>
  filter(name %in% c("Jane", "Mary")) |> 
  group_by(name, year) |> 
  summarize(n_distinct(num))

babynames |>
  filter(name %in% c("Jane", "Mary")) |> 
  group_by(name, year) |> 
  summarize(sum(name))

babynames |>
  filter(name %in% c("Jane", "Mary")) |> 
  group_by(name, year) |> 
  summarize(mean(num))

babynames |>
  filter(name %in% c("Jane", "Mary")) |> 
  group_by(name, year) |> 
  summarize(median(num))
```

[^31]: running the different code chunks with relevant output.

---

(@) Fill in Q1.[^32]
     (a) `gdp`
     (b) `year`
     (c) `gdpval`
     (d) `country`
     (e) `–country`

```{r}
#| echo: false
library(googlesheets4)
gs4_deauth()
GDP <- read_sheet("https://docs.google.com/spreadsheets/d/1RctTQmKB0hzbm1E8rGcufYdMshRdhmYdeL29nXqmvsc/pub?gid=0")
```

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "3"
GDP |>  
  select(country = starts_with("Income"), everything()) |> 
       pivot_longer(cols = Q1, 
                    names_to = Q2, 
                    values_to = Q3)
```

[^32]: e. `-country`

---

(@) Fill in Q2.[^33]
     (a) `gdp`
     (b) `year`
     (c) `gdpval`
     (d) `country`
     (e) `–country`

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "4"
GDP |>  
  select(country = starts_with("Income"), everything()) |> 
       pivot_longer(cols = Q1, 
                    names_to = Q2, 
                    values_to = Q3)
```

[^33]: b. `year`

---

(@) Fill in Q3.[^34]
     (a) `gdp`
     (b) `year`
     (c) `gdpval`
     (d) `country`
     (e) `–country`

```{r}
#| eval: false
#| echo: true
#| code-line-numbers: "5"
GDP |>  
  select(country = starts_with("Income"), everything()) |> 
       pivot_longer(cols = Q1, 
                    names_to = Q2, 
                    values_to = Q3)
```

[^34]: c. `gdpval`  (if possible, good idea to name variables something different from the name of the data frame)

---

(@) Response to stimulus (in ms) after only 3 hrs of sleep for 9 days. You want to make a plot with the subject's reaction time (y-axis) vs the number of days of sleep restriction (x-axis) using the following `ggplot()` code. Which data frame should you use?[^35]
    a. use raw data
    b. use `pivot_wider()` on raw data
    c. use `pivot_longer()` on raw data
    
```{r}
#| echo: true
#| eval: false
ggplot(___, aes(x = ___, y = ___, color = ___)) + 
  geom_line()
```

```{r}
#| echo: false
sleep_wide <- readr::read_csv("https://mac-stat.github.io/data/sleep_wide.csv")
sleep_wide
```

[^35]: c. use `pivot_longer()` on raw data.  The reference to the study is: Gregory Belenky, Nancy J. Wesensten, David R. Thorne, Maria L. Thomas, Helen C. Sing, Daniel P. Redmond, Michael B. Russo and Thomas J. Balkin (2003) Patterns of performance degradation and restoration during sleep restriction and subsequent recovery: a sleep dose-response study. Journal of Sleep Research 12, 1–12.

---

```{r}
#| echo: true
sleep_long <- sleep_wide |>
  pivot_longer(cols = -Subject,
               names_to = "day",
               names_prefix = "day_",
               values_to = "reaction_time")

sleep_long
```

---

(@) Consider band members from the Beatles and the Rolling Stones.  Who is removed in a `right_join()`?[^36]
   a. Mick
   b. John
   c. Paul
   d. Keith
   e. Impossible to know

```{r}
#| echo: true
#| eval: false
band_members |> 
  right_join(band_instruments, by = "name")
```

:::: {.columns}
::: {.column width="50%"}
```{r}
#| echo: true
band_members
```
:::

:::{.column width="50%"}
```{r}
#| echo: true
band_instruments
```
:::
::::

[^36]: a. Mick

---

(@) Consider band members from the Beatles and the Rolling Stones.  Which variables are removed in a `right_join()`?[^37]
   a. `name`
   b. `band`
   c. `plays`
   d. none of them

```{r}
#| echo: true
#| eval: false
band_members |> 
  right_join(band_instruments, by = "name")
```

:::: {.columns}
::: {.column width="50%"}
```{r}
#| echo: true
band_members
```
:::

:::{.column width="50%"}
```{r}
#| echo: true
band_instruments
```
:::
::::

[^37]: d. none of them (the default is to retain all the variables)

---

(@) What happens to Mick's `plays` variable in a `full_join()`?[^38]
   a. Mick is removed
   b. changes to guitar
   c. changes to bass
   d. `NA`
   e. `NULL`

```{r}
#| echo: true
#| eval: false
band_members |> 
  full_join(band_instruments, by = "name")
```

:::: {.columns}
::: {.column width="50%"}
```{r}
#| echo: true
band_members
```
:::

:::{.column width="50%"}
```{r}
#| echo: true
band_instruments
```
:::
::::

[^38]: d. `NA` (it would be `NULL` in **SQL**)
---

(@) Consider the `addTen()` function.  The following output is a result of which `map_*()` call?[^39]
   a. `map(c(1,4,7), addTen)`
   b. `map_dbl(c(1,4,7), addTen)`
   c. `map_chr(c(1,4,7), addTen)`
   d. `map_lgl(c(1,4,7), addTen)`
   
```{r}
#| echo: true
addTen <- function(wow) {
  return(wow + 10)
}
```
```{r}
#| echo: false
map_chr(c(1,4,7), addTen)
```

[^39]: c. `map_chr(c(1,4,7), addTen)` because the output is in quotes, the values are strings, not numbers.

---

(@) Which of the following input is allowed?[^40]
    a. `map(c(1, 4, 7), addTen)`
    b. `map(list(1, 4, 7), addTen)`
    c. `map(data.frame(a=1, b=4, c=7), addTen)`
    d. some of the above
    e. all of the above

[^40]: e. all of the above.  The `map()` function allows vectors, lists, and data frames as input.

---

(@) Which of the following produces a different output?[^41]
    a. `map(c(1, 4, 7), addTen)`
    b. `map(c(1, 4, 7), ~addTen(.x))`
    c. `map(c(1, 4, 7), ~addTen)`
    d. `map(c(1, 4, 7), function(hi) (hi + 10))`
    e. `map(c(1, 4, 7), ~(.x + 10))`
    
[^41]: c. `map(c(1, 4, 7), ~addTen)`.  The `~` acts on functions that do not have their own name or that are defined by `function(...)`.  By adding the argument `(.x)` we've expanded the `addTen()` function, and so it needs a `~`.  The `addTen()` function all alone does not use a `~`.

---

(@) What will the following code output?[^42]
    a. 3 random normals
    b. 6 random normals
    c. 18 random normals
    
```{r}
#| echo: false
#| eval: true
input <- tibble::tribble(
  ~ n, ~ mean, ~ sd,
   1,     1,    3,
   2,    3,   1,
   3,   47,  10
)
```
```{r}
#| echo: true
#| eval: true
input
```

```{r}
#| echo: true
#| eval: false
input |> 
  pmap(rnorm)
```
[^42]: b. 6 random normals (1 with mean 1, sd 3; 2 with mean 3, sd 1; 3 with mean 47, sd 10)

---

(@) In R the `ifelse()` function takes the arguments:[^43]
   a. question, yes, no
   b. question, no, yes
   c. statement, yes, no
   d. statement, no, yes
   e. option1, option2, option3


[^43]: a. question, yes, no

---

(@) What is the output of the following:[^44]
    a.	"cat", 30, "cat", "cat", 6 
    b.	"cat", "30", "cat", "cat", "6"
    c.	1, "cat", 5, "cat", "cat"
    d.	1, "cat", 5, NA, "cat"
    e.	"1", "cat", "5", NA, "cat"

```{r}
#| eval: false
#| echo: true
data <- c(1, 30, 5, NA, 6)

ifelse(data > 5, "cat", data)
```

[^44]: e.	"1", "cat", "5", NA, "cat"  (Note that the numbers were converted to character strings!)

---

(@) In R, the `set.seed()` function[^45]
   a. makes your computations go faster
   b. keeps track of your computation time
   c. provides an important parameter
   d. repeats the function
   e. makes your results reproducible

[^45]: e. makes your results reproducible


---

(@) If I run a hypothesis test with a type I error cut off of $\alpha = 0.05$ and the null hypothesis is true, what is the probability of rejecting $H_0$?[^46]
   a. 0.01
   b. 0.05
   c. 0.1
   d. I don't know.
   e. No one knows.


[^46]: b. 0.05  If the null hypothesis is true and the technical conditions hold, then we should reject the null hypothesis $\alpha \cdot 100$% of the time.

---

(@) If I run a hypothesis test with a type I error cut off of $\alpha = 0.05$ and the null hypothesis is true, **and also the technical conditions do not hold** what is the probability of rejecting $H_0$?[^47]
   a. 0.01
   b. 0.05
   c. 0.1
   d. I don't know.
   e. No one knows.


[^47]: e. No one knows.  It totally depends on how and how much the technical conditions are violated and how resistant the test is to the technical conditions.

---

(@) If I run a hypothesis test with a type I error cut off of $\alpha = 0.05$ and **the null hypothesis is false**, what is the probability of rejecting $H_0$?[^48]
   a. 0.01
   b. 0.05
   c. 0.1
   d. I don't know.
   e. No one knows.


[^48]: e. No one knows.  It totally depends on the degree to which the null hypothesis is false.

---

(@) If I aim to create a 95% confidence interval, and the technical conditions hold, what is the probability that the CI will contain the true value of the parameter?[^49]
   a. 0.90
   b. 0.95
   c. 0.99
   d. I don't know.
   e. No one knows.


[^49]: b. 0.95  If the technical conditions hold, 95% of all confidence intervals should contain the true parameter.

---

(@) If I aim to create a 95% confidence interval, and **the technical conditions do not hold**, what is the probability that the CI will contain the true value of the parameter?[^50]
   a. 0.90
   b. 0.95
   c. 0.99
   d. I don't know.
   e. No one knows.


[^50]: e. No one knows.  If the technical conditions do not hold, the CI may or may not contain the true value of the parameter at the given confidence level (i.e., 95%).

---

(@) We typically compare means (across two groups) instead of medians because:[^51]
   a. we don’t know the SE of the difference of medians
   b. means are inherently more interesting than medians
   c. permutation tests don’t work with medians
   d. the Central Limit Theorem doesn’t apply for medians.
   
[^51]: d. the Central Limit Theorem doesn’t apply for medians.

---

(@) What are the technical assumptions for a t-test?[^52]
   a. none
   b. normal data
   c. $n \geq 30$
   d. random sampling / random allocation for appropriate conclusions

[^52]: we always need d. random sampling / random allocation for appropriate conclusions.  The theory is derived from b. normal data.  If c. $n \geq 30$, then the theory holds really well, regardless of whether the data are normal.

---

(@) What are the technical conditions for permutation tests?[^53]
   a. none
   b. normal data
   c. $n \geq 30$
   d. random sampling / random allocation for appropriate conclusions
   
[^53]: d. random sampling / random allocation for appropriate conclusions
   
---

(@) Follow up to permutation test:  the assumptions change based on whether the statistic used is the mean, median, proportion, etc.[^54]
   a. TRUE
   b. FALSE

[^54]: b. FALSE

---

(@) Why care about the distribution of the test statistic?[^55]
   a. Better estimator
   b. So we can find rejection region
   c. So we can control power
   d. Because we love the CLT
   
[^55]: b. So we can find rejection region

---

(@) Given statistic T = r(X), how do we find a (reasonable) test?[^56]
   a. Maximize power
   b. Minimize type I error
   c. Control type I error
   d. Minimize type II error
   e. Control type II error

[^56]: c. Control type I error

---

(@) Type I error is[^57]
   a. We give him a raise when he deserves it.
   b. We don’t give him a raise when he deserves it.
   c. We give him a raise when he doesn’t deserve it.
   d. We don’t give him a raise when he doesn’t deserve it.

[^57]: c. We give him a raise when he doesn’t deserve it.

---

(@) Type II error is[^58]
   a. We give him a raise when he deserves it.
   b. We don’t give him a raise when he deserves it.
   c. We give him a raise when he doesn’t deserve it.
   d. We don’t give him a raise when he doesn’t deserve it.

[^58]: b. We don’t give him a raise when he deserves it.

---

(@) Power is the probability that:[^59]
   a. We give him a raise when he deserves it.
   b. We don’t give him a raise when he deserves it.
   c. We give him a raise when he doesn’t deserve it.
   d. We don’t give him a raise when he doesn’t deserve it.

[^59]: a. We give him a raise when he deserves it.

---

(@) Why don’t we always reject H0?[^60]
   a. type I error too high
   b. type II error too high
   c. level of sig too high
   d. power too high

[^60]: a. type I error too high

---

(@) The player is more worried about[^61]
   a. A type I error
   b. A type II error

[^61]: b. A type II error

---

(@) The coach is more worried about[^62]
   a. A type I error
   b. A type II error

[^62]: a. A type I error

---

(@) Increasing your sample size[^63]
   a. Increases your power
   b. Decreases your power
   
[^63]: a. Increases your power

---

(@) Making your significance level more stringent ($\alpha$ smaller)[^64]
   a. Increases your power
   b. Decreases your power

[^64]: a. Increases your power

---

(@) A more extreme alternative[^65]
   a. Increases your power
   b. Decreases your power
   
[^65]: a. Increases your power

---

(@) What is the primary reason to use a permutation test (instead of a test built on calculus)?[^66]
   a. more power
   b. lower type I error
   c. more resistant to outliers
   d. can be done on statistics with unknown sampling distributions

[^66]: d. can be done on statistics with unknown sampling distributions

---

(@) What is the primary reason to bootstrap a CI (instead of creating a CI from calculus)?[^67]
   a. larger coverage probabilities
   b. narrower intervals
   c. more resistant to outliers
   d. can be done on statistics with unknown sampling distributions

[^67]: d. can be done on statistics with unknown sampling distributions

---

(@) You have a sample of size n = 50.  You sample with replacement 1000 times to get 1000 bootstrap samples. What is the sample size of each bootstrap sample?[^68]
   a. 50
   b. 1000

[^68]: a. 50

---

(@) You have a sample of size n = 50.  You sample with replacement 1000 times to get 1000 bootstrap samples. How many bootstrap statistics will you have?[^69]
   a. 50
   b. 1000

[^69]: b. 1000

---

(@) The bootstrap distribution is centered around the[^70]
   a. population parameter
   b. sample statistic
   c. bootstrap statistic
   d. bootstrap parameter

[^70]: b. sample statistic

---

(NEED TO ADD A PLOT FROM STATKEY HERE)

(@) 95% CI for the difference in proportions:[^71]
   a. (0.39, 0.43)
   b. (0.37, 0.45)
   c. (0.77, 0.81)
   d. (0.75, 0.85)

[^71]: depends on the plot

---

(@) Suppose a 95% bootstrap CI for the difference in means was (3,9), would you reject H0?[^72] (uh... What is the null hypothesis here???)
   a. yes
   b. no
   c. not enough information to know

[^72]: a. yes (because the interval for the true difference in population means does not overlap zero.)

---

(@) Given the situation where $H_a$ is TRUE.  Consider 100 CIs (for true difference in means, where each of the 100 CIs is created using a different dataset). The power of the test can be approximated by:[^73]
   a. The proportion that contain the true difference in means.
   b. The proportion that do not contain the true difference in means.
   c. The proportion that contain zero.
   d. The proportion that do not contain zero.

[^73]: d. The proportion that do not contain zero.


---

