[
  {
    "path": "posts/2021-12-07-extensions/",
    "title": "14. Awesome extensions",
    "description": "So many topics, so little time.  A short survey on some of the many many topics we could have covered but didn't.",
    "author": [
      {
        "name": "Johanna Hardin",
        "url": "https://m154-comp-stats.netlify.app/"
      }
    ],
    "date": "2021-12-07",
    "categories": [],
    "contents": "\n\n\n\nFigure 1: Artwork by @allison_horst.\n\n\n\nAgenda \nDecember 7, 2021\nReturn clickers\nWhat’s next\nCourse Evaluations\nReadings \nClass notes: Extensions\nSilge and Robinson (2021), Text Mining with R.\nReflection questions \nWhat do I love most about the methods we’ve been covering? The math? The statistics? The programming? The algorithms? The data? The ethical quandaries?\nThe whale shark above is a graphic meant to help understand principal components. Yet one more thing we didn’t touch on, but could have.\nEthics considerations \nKeeping asking yourself:\nHow do I stay accountable for my work?\nHow might others be impacted by what I’ve created?\nWhere did the data come from, and what biases might be inherent?\nWhat population is appropriate for any of the inferential claims I’m making?\nHow might individual’s privacy or anonymity be impacted by what I’ve created?\nIs it possible that my work could be misinterpreted or misused?\n\nSlides \nIn class slides - extensions for 12/07/21.\nAdditional Resources \nJulia Silge’s blog many string examples\nNate Silver and Galen Druke of 538 talk about the problems with using sentiment analysis to measure whether the mainstream media is more biased against Biden or Trump. Is The Media Tougher On Biden Than Trump?\n\n\n\n",
    "preview": "posts/2021-12-07-extensions/../../images/whalekrill.png",
    "last_modified": "2022-01-15T18:37:53-08:00",
    "input_file": {},
    "preview_width": 2154,
    "preview_height": 786
  },
  {
    "path": "posts/2021-11-30-review2/",
    "title": "13. Second half review",
    "description": "Resources for review of the second half of the semester.",
    "author": [
      {
        "name": "Johanna Hardin",
        "url": "https://m154-comp-stats.netlify.app/"
      }
    ],
    "date": "2021-11-30",
    "categories": [],
    "contents": "\n\n\n\nFigure 1: Artwork by @allison_horst.\n\n\n\nAgenda \nNovember 30, 2021\nReflection on supervised & unsupervised learning\nQ & A\nTake home 2 due at midnight.\nDecember 2 & 3, 2021\nOffice hours during class\nExam some time on Thursday or Friday\nTake home due Tuesday, November 30, 11:59pm\nReadings \nSample questions\nClicker questions\nReflection questions \nEach week’s reflection questions are given separately, see the Daily (read: weekly) pages.\nEthics considerations \nEach week’s ethics considerations are given separately, see the Daily (read: weekly) pages.\nSlides \nEach week’s slides are given separately, see the Daily (read: weekly) pages.\nEach week’s warm-up solutions are given separately, see the Daily (read: weekly) pages.\nAdditional Resources \nEach week’s warm-up exercises are given separately, see the Daily (read: weekly) pages.\nAll solutions to HW (including the assignments that weren’t due, like HW 11 on clustering) are on Sakai.\n\n\n\n",
    "preview": "posts/2021-11-30-review2/../../images/nominal_ordinal_binary.png",
    "last_modified": "2022-01-15T18:37:47-08:00",
    "input_file": {},
    "preview_width": 5000,
    "preview_height": 3060
  },
  {
    "path": "posts/2021-11-18-clustering/",
    "title": "12. Clustering",
    "description": "A quick dive into unsupervised methods.  We cover two clutering methods: partitioning (k-means and k-medoids) and hierarchical.",
    "author": [
      {
        "name": "Johanna Hardin",
        "url": "https://m154-comp-stats.netlify.app/"
      }
    ],
    "date": "2021-11-18",
    "categories": [],
    "contents": "\n\n\n\nFigure 1: Artwork by @allison_horst.\n\n\n\nAgenda \nNovember 16, 2021\nunsupervised methods\nNovember 18, 2021\nk-means clustering\nk-medoid clustering\nNovember 23, 2021\nhierarchical clustering\nReadings \nClass notes: Unsupervised Learning\nGareth, Witten, Hastie, and Tibshirani (2021), Unsupervised Learning (Chapter 12)  Introduction to Statistical Learning.\nReflection questions \nWhy does the plot of within-cluster sum of squares vs. \\(k\\) make an elbow-shape (hint: think about \\(k\\) as it ranges from 1 to \\(n)?\\)\nHow are the centers of the clusters in \\(k\\)-means calculated? What about in \\(k\\)-medoids?\nWill a different initialization of the cluster centers always produce the same cluster output?\nHow do distance metrics change a hierarchical clustering?\nHow can you choose \\(k\\) with hierarchical clustering?\nWhat is the difference between single, average, and complete linkage in hierarchical clustering?\nWhat is the difference between agglomerative and divisive hierarchical clustering?\nEthics considerations \nWhat type of feature engineering is required for \\(k\\)-means / hierarchical clustering?\nHow do you (can you?) know if your clustering has uncovered any real patterns in the data?\nSlides \nIn class slides - clustering for 11/18/21 and 11/23/21.\nWU19 - k-means clustering\nWU20 - hierarchical clustering\nAdditional Resources \nFantastic k-means applet by Naftali Harris.\nAnalyzing networks of characters in ‘Love Actually’\nNetwork Analysis of political books – Bridging the divide: political books\n\n\n\n",
    "preview": "posts/2021-11-18-clustering/../../images/kmeans_5.jpg",
    "last_modified": "2022-01-15T18:37:38-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-11-09-svm/",
    "title": "11. Support Vector Machines",
    "description": "Here, support vector machines will be used only to classify objects which can be categorized into one of exactly two classes.  As with other classification and regression methods, support vector machines as a method can be used more generally.  However, we will work to understand the mathematical derivation of the binary-classification SVM.",
    "author": [
      {
        "name": "Johanna Hardin",
        "url": "https://m154-comp-stats.netlify.app/"
      }
    ],
    "date": "2021-11-09",
    "categories": [],
    "contents": "\n\n\n\nFigure 1: Artwork by @allison_horst.\n\n\n\nAgenda \nNovember 9, 2021\nlinearly separable\ndot products\nsupport vector formulation\nNovember 11, 2021\nnot linearly separable (SVM)\nkernels (SVM)\nsupport vector formulation\nReadings \nClass notes: Support Vector Machines\nGareth, Witten, Hastie, and Tibshirani (2021), Support Vector Machines (Chapter 9)  Introduction to Statistical Learning.\nMax Kuhn and Julia Silge (2021), Tidy Modeling with R\nReflection questions \nHow is an SVM built (how do we find the model)?\nWhy is it often advantageous to transform the data into a higher dimensional space?\nWhat is the kernel trick and how is it related to the SVM decision rule?\nCan SVMs work on data that are not linearly separable (even in high dimensions)? How?\nWhat are the advantages of the SVM algorithm?\nWhat are the disadvantages of the SVM algorithm?\nEthics considerations \nWhat type of feature engineering is required for Support Vector Machines?\nDo Support Vector Machines produce a closed form “model” that can be written down or visualized and handed to a client?\nIf the model produces near perfect predictions on the test data, what are some potential concerns about putting that model into production?\nSlides \nIn class slides - support vector machines for 11/9/21 and 11/11/21.\nWU16 - SVM 1\nWU17 - SVM 2\nWU18 - SVM 3\nAdditional Resources \nROC curve of science\nTidymodels SVM vignette\nJulia Silge’s blog SVMs to predict if a post office is in Hawaii\nJulia Silge’s blog SVMs to predict Netflix shows as TV or movies\n\n\n\n",
    "preview": "posts/2021-11-09-svm/../../images/monster_support.jpg",
    "last_modified": "2022-01-15T18:37:32-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-11-02-rf/",
    "title": "10. Random Forests",
    "description": "Many trees make a forest.  Bagging gives FREE independent model assessment or parameter tuning.  Random Forests have a fantastic variance - bias trade-off.",
    "author": [
      {
        "name": "Johanna Hardin",
        "url": "https://m154-comp-stats.netlify.app/"
      }
    ],
    "date": "2021-11-02",
    "categories": [],
    "contents": "\n\n\n\nFigure 1: Artwork by @allison_horst.\n\n\n\nAgenda \nNovember 2, 2021\nRedux - CART\nbagging process\nbagging error rate (OOB error)\nNovember 4, 2021\nRandom Forests\nExample\nReadings \nClass notes: bagging\nClass notes: random forests\nGareth, Witten, Hastie, and Tibshirani (2021), bagging & random forests (section 8.2)  Introduction to Statistical Learning.\nMax Kuhn and Julia Silge (2021), Tidy Modeling with R\nReflection questions \nHow does bagging improve on a single tree? How does tuning mtry (with aggregation) improve on a single tree? (That is, what advantage do forests have over single trees.)\nHow do Random Forests make predictions on test data?\nCan Random Forests be used for both classification and regression or only one of the two tasks?\nCan you use categorical / character predictors with Random Forests?\nHow are mtry and the number of trees chosen?\nHow do the bias and variance change for different values of mtry and number of trees?\nWhat are the advantages of the Random Forests algorithm?\nWhat are the disadvantages of the Random Forest algorithm?\nEthics considerations \nWhat type of feature engineering is required for Random Forests?\nDo Random Forests produce a closed form “model” that can be written down or visualized and handed to a client?\nIf the model produces near perfect predictions on the test data, what are some potential concerns about putting that model into production?\nSlides \nIn class slides - bagging & random forests for 11/2/21 and 11/4/21.\nFrom last week: WU14 - CART\nWU15 - Bagging\nAdditional Resources \nThe end of science (???) “The End of Theory: The Data Deluge Makes the Scientific Method Obsolete”, Science, June 23, 2008.\nMaybe not so fast. “10 things statistics taught us about big data analysis”, Jeff Leek, May 22, 2014.\nJulia Silge’s blog <a href = “https://juliasilge.com/blog/sf-trees-random-tuning/” target_“blank”>Tuning Random Forest parameters\nJulia Silge’s blog <a href = “https://juliasilge.com/blog/water-sources/” target_“blank”>Predicting water sources with Random Forests\n\n\n\n",
    "preview": "posts/2021-11-02-rf/../../images/parsnip.png",
    "last_modified": "2022-01-15T18:37:18-08:00",
    "input_file": {},
    "preview_width": 6569,
    "preview_height": 4086
  },
  {
    "path": "posts/2021-10-26-knn-trees/",
    "title": "9. k-NN + trees",
    "description": "k-Nearest Neighbors is a classification algorithm based on the premise that points which are close to one another (in some predictor space) are likely to be similar with respect to the outcome variable.  trees represent a set of methods where prediction is based on majority vote or average outcome based on a partition of the predictor space.",
    "author": [
      {
        "name": "Johanna Hardin",
        "url": "https://m154-comp-stats.netlify.app/"
      }
    ],
    "date": "2021-10-26",
    "categories": [],
    "contents": "\n\n\n\nFigure 1: Artwork by @allison_horst.\n\n\n\nAgenda \nOctober 26, 2021\nRedux - model process\n\\(k\\)-Nearest Neighbors\nCross Validation\nExample\nOctober 28, 2021\nDecision Trees\nExample\nReadings \nClass notes: k nearest neighbors\nClass notes: decision trees\nGareth, Witten, Hastie, and Tibshirani (2021), k Nearest Neighbors (section 3.5)  Introduction to Statistical Learning.\nGareth, Witten, Hastie, and Tibshirani (2021), the basics of decision trees (section 8.1)  Introduction to Statistical Learning.\nMax Kuhn and Julia Silge (2021), Tidy Modeling with R\nReflection questions \nWhat is the “\\(k\\)” in \\(k\\)-Nearest Neighbors? What does CART stand for?\nWhy do most implementations of \\(k\\)-NN prefer odd values of k?\nHow does \\(k\\)-NN / CART make predictions on test data?\nCan \\(k\\)-NN / CART be used for both classification and regression or only one of the two tasks?\nCan you use categorical / character predictors with \\(k\\)-NN / CART?\nHow is \\(k\\) / tree depth chosen?\nWhat does it mean for CART to be high variance? How do the bias and variance change for different values of \\(k\\) in \\(k\\)-NN?\nWhat are the advantages of the \\(k\\)-NN / CART algorithm?\nWhat are the disadvantages of the \\(k\\)-NN / CART algorithm?\nEthics considerations \nWhat type of feature engineering is required for \\(k\\)-NN / CART?\nWhy is it recommended that \\(k\\)-NN not be used on large datasets?\n(For a given \\(k\\)) why does \\(k\\)-NN use more computation time to test than to train? [n.b., the opposite is true for the majority of classification and regression algorithms.]\nIf the model produces near perfect predictions on the test data, what are some potential concerns about putting that model into production?\nSlides \nIn class slides - knn for 10/26/21.\nIn class slides - decision trees for 10/28/21.\nWU13 - k-NN\nWU14 - trees\nAdditional Resources \nWhy the Bronx really burned – “adjusting” data to give the wrong information. FiveThirtyEight, Jody Avirgan, 10/29/2015.\n\nWith the help of the Rand Corp., the city tried to measure fire response times, identify redundancies in service, and close or re-allocate fire stations accordingly. What resulted, though, was a perfect storm of bad data: The methodology was flawed, the analysis was rife with biases, and the results were interpreted in a way that stacked the deck against poorer neighborhoods. The slower response times allowed smaller fires to rage uncontrolled in the city’s most vulnerable communities.\n\nSF vs. NYC housing – a great example of a classification tree.\nJulia Silge’s blog <a href = “https://juliasilge.com/blog/scooby-doo/” target_“blank”>Tuning Decision Trees\n\n\n\n",
    "preview": "posts/2021-10-26-knn-trees/../../images/dragon_predict_mlr.png",
    "last_modified": "2022-01-15T18:37:03-08:00",
    "input_file": {},
    "preview_width": 2156,
    "preview_height": 1463
  },
  {
    "path": "posts/2021-10-21-recipes/",
    "title": "8. Recipes",
    "description": "And old adage says: garbage in, garbage out.  Here we avoid garbage in.",
    "author": [
      {
        "name": "Johanna Hardin",
        "url": "https://m154-comp-stats.netlify.app/"
      }
    ],
    "date": "2021-10-21",
    "categories": [],
    "contents": "\n\n\n\nFigure 1: Artwork by @allison_horst.\n\n\n\nAgenda \nOctober 21, 2021\nWhat needs to be done to the data?\ntidymodels syntax for recipes\nExample\nReadings \nClass notes: k nearest neighbors\nMax Kuhn and Julia Silge (2021), Tidy Modeling with R\nReflection questions \nWhat is the process for building a model using tidymodels?\nWhy is it important to do feature engineering for variables in a model?\nHow is data separated in order to work with independent information (hint: two ways)?\nEthics considerations \nThere are two ways that laws are enforced (both equally important):\ndisparate treatment \\(\\rightarrow\\) means that the differential treatment is intentional\ndisparate impact \\(\\rightarrow\\) means that the differential treatment is unintentional or implicit (some examples include advancing mortgage credit, employment selection, predictive policing)\n\nAnti-discrimination Laws\nCivil Rights Acts of 1964 and 1991\nAmericans with Disabilities Act\nGenetic Information Nondiscrimination Act\nEqual Credit Opportunity Act\nFair Housing Act\n\nQuestions to ask yourself in every single data analysis you perform (taken from Data Science for Social Good at the University of Chicago):\nWhat biases may exist in the data you’ve been given? How can you find out?\nHow will your choices with tuning parameters affect different populations represented in the data?\nHow do you know you aren’t getting the right answer to the wrong question?\nHow would you justify what you’d built to someone whose welfare is made worse off by the implementation of your algorithm?\nSee the slides on bias in modeling (9/23/21) for times when there are no inherent biases but the structure of the data create unequal model results.\n\nSlides \nIn class slides for 10/21/21.\nWU12 - feature engineering\nAdditional Resources \nHilary Mason describing what is machine learning to 5 different people.\nJulia Silge’s blog is full of complete tidymodels examples and screencasts.\nAlexandria Ocasio-Cortez, Jan 22, 2019 MLK event with Ta-Nehisi Coates\nS. Barocas and A. Selbst, “Big Data’s Disparate Impact”, California Law Review, 671, 2016.\nMachine Bias in Pro Publica by Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner, May 23, 2016\nAlgorithmic Justice League is a collective that aims to:\nHighlight algorithmic bias through media, art, and science\nProvide space for people to voice concerns and experiences with coded bias\nDevelop practices for accountability during design, development, and deployment of coded systems\nJoy Buolamwini – AI, Ain’t I A Woman?\n\n\n\n\n",
    "preview": "posts/2021-10-21-recipes/../../images/recipes.png",
    "last_modified": "2022-01-15T18:37:09-08:00",
    "input_file": {},
    "preview_width": 6322,
    "preview_height": 3578
  },
  {
    "path": "posts/2021-09-28-permutation/",
    "title": "5. Permutation Tests",
    "description": "Simulating scenarios, simulating datasets, simulating random variables.",
    "author": [
      {
        "name": "Johanna Hardin",
        "url": "https://m154-comp-stats.netlify.app/"
      }
    ],
    "date": "2021-09-28",
    "categories": [],
    "contents": "\n\n\n\nFigure 1: Artwork by @allison_horst.\n\n\n\nAgenda \nSeptember 28, 2021\nReview: logic of hypothesis testing\nLogic of permutation tests\nExamples - 2 samples and beyond\nSeptember 30, 2021\nConditions, exchangeability, random structure\nDifferent statistics within the permutation test\nPower\nPermutation vs. Randomization tests (Binomial)\nReadings \nClass notes: Permutation Tests\nBaumer, Horton, and Kaplan (2021), Simulation (Chp 13) in Modern Data Science for R.\nReflection questions \nWhat is a test statistic?\nWhat is a p-value?\nWhy for a two sample comparison (treatment A vs treatment B) is it okay to use \\(\\overline{X}_A - \\overline{X}_B\\) for a test statistic in a permutation test, but for a t-test the test statistic is necessarily \\(t^* = \\frac{\\overline{X}_A - \\overline{X}_B}{\\sqrt{s^2_A/n_A + s^2_B/n_B}}\\) (that is, divided by a measure of variability)?\nHow do you know what to permute in order to create a null sampling distribution?\nWhat does “exchangeability” mean (as a technical condition) when discussing permutation tests?\nWhat is the difference between a permutation test and a randomization test? Are there times when doing a randomization test is possible?\nWhat is power? What are type I and type II errors?\nEthics considerations \nIn a permutation test, sometimes there are many test statistics to choose from (which address the same hypotheses). Why wouldn’t you want to try them all and choose the one that gives you the highest level of significance?\nWhen is it acceptable to claim that the resulting “significant” outcome is actually a causal relationship (and not just an association)?\nSlides \nIn class slides for both 9/28/21 and 9/30/21.\nWU8 - HT logic\nWU9 - Permuting\nAdditional Resources \nRossman & Chance applets:\nanalytic test of 2 means (t-test)\npermutation test of 2 means\nanalytic test of many means (ANOVA)\npermutation test of many means\nconfidence intervals\npower\nlinear models\n\nStatistics without the agonizing pain - John Rauser at Strata + Hadoop 2014\nThe algorithm that could end partisan gerrymandering\nRStudio cheatsheets – there is one on purrr!\n\n\n\n",
    "preview": "posts/2021-09-28-permutation/../../images/not_normal.png",
    "last_modified": "2022-01-15T18:36:36-08:00",
    "input_file": {},
    "preview_width": 2320,
    "preview_height": 1790
  },
  {
    "path": "posts/2021-09-21-simulating/",
    "title": "4. Simulating",
    "description": "Simulating scenarios, simulating datasets, simulating random variables.",
    "author": [
      {
        "name": "Johanna Hardin",
        "url": "https://m154-comp-stats.netlify.app/"
      }
    ],
    "date": "2021-09-21",
    "categories": [],
    "contents": "\n\n\n\nFigure 1: Artwork by @allison_horst.\n\n\n\nAgenda \nSeptember 21, 2021\nWhy simulate?\nWhat makes a good simulation?\nExamples\nSeptember 23, 2021\nBias in modeling\nSimulating statistical inference\nReadings \nClass notes: Simulating\nBaumer, Horton, and Kaplan (2021), Iteration (Chp 7) in Modern Data Science for R.\nReflection questions \nWhat are some reasons to simulate?\nWhat makes a good simulation?\nWhat does “90%” mean when describing a 90% confidence interval? (That is, 90% of what?)\nWhat does a type I error rate mean when doing hypothesis testing? (That is, rate of what?)\nThe p-value is the probability of obtaining the observed data or more extreme if the null hypothesis is true. If probability is interpreted in the long-run-frequency definition, what is happening repeatedly so as to conceptualize the probability of something happening?\nEthics considerations \nHow can we use simulations to understand algorithmic bias or other types of problems in modeling?\nWhat does it mean for two different populations to have different feature distributions?\nSlides \nIn class slides for both 9/21/21 and 9/23/21.\nWU6 - Simulating\nWU7 - Simulating CIs\nAdditional Resources \nRStudio cheatsheets – there is one on purrr!\nSimulating who would be in the first GOP debate (NYT 7/29/15)\nBlog by Aaron Roth, Algorithmic Unfairness Without Any Bias Baked In.\nSimulating linear models from the ISCAM applets.\n\n\n\n",
    "preview": "posts/2021-09-21-simulating/../../images/map_frosting.png",
    "last_modified": "2022-01-15T18:36:30-08:00",
    "input_file": {},
    "preview_width": 5869,
    "preview_height": 3500
  },
  {
    "path": "posts/2021-09-14-wrangling/",
    "title": "3. Wrangling",
    "description": "Data wrangling skills are among the most important to hone.",
    "author": [
      {
        "name": "Jo Hardin",
        "url": "https://m154-comp-stats.netlify.app/"
      }
    ],
    "date": "2021-09-14",
    "categories": [],
    "contents": "\n\n\n\nFigure 1: Artwork by @allison_horst.\n\n\n\nAgenda \nSeptember 14, 2021\nTidy data\nData verbs\nSeptember 16, 2021\nRelational data (_join)\npivoting\nmapping\nlubridate\nReadings \nClass notes: Data Wrangling\nWickham (2017) Data transformation and Tidy data in R for Data Science.\nIf you aren’t super comfortable with R yet, check out Workflow: basics in R for Data Science.\nReflection questions \nHow and why is %>% used? And how is it different from the layering symbol + used in ggplot()?\nWhat are the main data wrangling verbs?\nHow do you distinguish the different _join functions? Are the _join keys formatted in the same way across the two datasets? Are the data recorded in the same way (e.g., is age birthday or age at recording?) ?\nWhat are some of the ways to distinguish a data verb from a typical function?\nEthics considerations \nWhat is Jan 31 plus one month? And why does it matter that every analysis we do is a series of decisions? Keeping in mind that each of us might make a different decision, and all decisions have consequences.\nSlides \nIn class slides for both 9/14/21 and 9/16/21.\nWU4 - verbs\nWU5 - joining\nAdditional Resources \nRStudio cheatsheets\ntidyverse vignettes\npivoting\n\n\n\n",
    "preview": "posts/2021-09-14-wrangling/../../images/dplyr_wrangling.png",
    "last_modified": "2022-01-15T18:36:14-08:00",
    "input_file": {},
    "preview_width": 1913,
    "preview_height": 1530
  },
  {
    "path": "posts/2021-09-07-dataviz/",
    "title": "2. Data Viz",
    "description": "Examples, good and bad.  Theory underlying what makes a viz good and bad.  Tools to implement viz tasks.",
    "author": [
      {
        "name": "Jo Hardin",
        "url": "https://m154-comp-stats.netlify.app/"
      }
    ],
    "date": "2021-09-07",
    "categories": [],
    "contents": "\n\n\n\nFigure 1: Artwork by @allison_horst.\n\n\n\nAgenda \nSeptember 7, 2021\nCholera: what went (didn’t go) well with the graphics?\nChallenger: what didn’t go (went) well with the graphics?\nThoughts on plotting (with example(s))\nClass discussion will be based on Tufte (1997) Visual and Statistical Thinking: Displays of Evidence for Making Decisions. (Use Google to find it.)\nAnother great reference is the following text: Fundamentals of Data Visualization by Wilke at http://serialmentor.com/dataviz/\nSeptember 9, 2021\nGrammar of graphics\nggplot\nReadings \nClass notes: Visualization\nTufte (1997) Visual and Statistical Thinking: Displays of Evidence for Making Decisions. (Use Google to find it.)\nWickham (2017) Data Visualization in R for Data Science.\nReflection questions \nWhen creating a graph, try to sketch / image the graph before you code it. What do you want R to do (what is the goal)? In order to do that, what does R need to know?\nWhat should the goal of a plot be? What should the goal of your plot be?\nWhat different aspects deconstruct a plot?\nEthics considerations \nDoes your plot make the comparison of interest: easily? and accurately?\nDid you add alt text to your images (see Writing Alt Text for Data Visualization)?\nIs your plot accessible to those who are color blind or looking at the image in black and white?\nSlides \nIn class slides for both 9/7/21 and 9/9/21.\nWU2 - Tufte\nWU3 - ggplot\nAdditional Resources \nDuBois’s images online and in W.E.B. Du Bois’s Data Portraits: Visualizing Black America, a compilation edited by Whitney Battle-Baptiste.\nFlowcharts for choosing appropriate plots, brief tutorials of viz types, and source code in R and Python: from Data to Viz\nSee something or Say Something\nCensus trends visualized\nVisualization Internship (Fall 2021) at 538\nvisualizing data: Digest of the best visualizations from the past month\nA regular NYT column on visualizations: What’s Going on in this Graph?\nStudies about visualizations and perception\nFundamentals of Data Visualization\n\n\n\n",
    "preview": "posts/2021-09-07-dataviz/../../images/ggplot2_masterpiece.png",
    "last_modified": "2022-01-15T18:32:52-08:00",
    "input_file": {},
    "preview_width": 2080,
    "preview_height": 1566
  },
  {
    "path": "posts/2021-08-31-getting-started/",
    "title": "1. Start with R + Git",
    "description": "The importance of reproducibility.  Ideas of computational statistics, data science, and machine learning.  Some resources for starting with R + RStudio + Git + GitHub.",
    "author": [
      {
        "name": "Jo Hardin",
        "url": "https://m154-comp-stats.netlify.app/"
      }
    ],
    "date": "2021-08-31",
    "categories": [],
    "contents": "\n\n\n\nFigure 1: Artwork by @allison_horst.\n\n\n\nAgenda \nAugust 31, 2021\nQuestionnaire\nSyllabus & Course Outline\nStitch Fix Algorithm\nCollege Rankings\nCan Twitter predict election results?\nBefore next Thursday, listen to the full conversation of Not So Standard Deviations - Compromised Shoe Situation.\nSeptember 2, 2021\nReproducibility & GitHub\nDesign Challenge (Not So Standard Deviations)\nBefore next Tuesday, read: Tufte. 1997. Visual and Statistical Thinking: Displays of Evidence for Making Decisions. (Use Google to find it.)\nReadings \nThe syllabus\nModern Data Science with R Prologue\nClass notes: Introduction\nWhy Git? + monsters\nReflection questions \nWhat can statistics & data science do? How do they do that?\nWhat can’t statistics & data science do? Why not?\nWhat choices were made to collect the Twitter data?\nWhat choices were made to model the Twitter data?\nWhat are the advantages and disadvantages of high touch versus low touch data?\nEthics considerations \nWhy is it problematic if the analysis isn’t reproducible?\nIs every analysis worth doing? (e.g., time to get to work, predicting presidential results, etc.). Can the act of doing the analysis be ethically questionable?\nSlides \nIn class slides for both 8/31/21 and 9/2/21.\nTwitter activity\nWU1 - working with R\nAdditional Resources \nGreat algorithm for the whole process\nDesign Challenge (Not So Standard Deviations), listen to the full conversation.\nVideo (less than 2 min) on the strengths of reproducible research\nR vs. Python? (My personal opinion is that neither of the languages is “best”.)\n2017 Kaggle user survey and  2019 Stack Overflow Developer Survey\nPNAS paper retracted due to problems with figure and reproducibility (April 2016)\nAnalysis of Trump’s tweets with evidence that someone else tweets from his account using an iPhone part 1 and part 2 \n\n\n\n",
    "preview": "posts/2021-08-31-getting-started/../../images/reproducibility_court.png",
    "last_modified": "2022-07-27T19:46:08-07:00",
    "input_file": "getting-started.knit.md",
    "preview_width": 4678,
    "preview_height": 2814
  },
  {
    "path": "posts/2021-10-12-review1/",
    "title": "7. First half review",
    "description": "Resources for review of the first half of the semester.",
    "author": [
      {
        "name": "Johanna Hardin",
        "url": "https://m154-comp-stats.netlify.app/"
      }
    ],
    "date": "2020-10-12",
    "categories": [],
    "contents": "\n\n\n\nFigure 1: Artwork by @allison_horst.\n\n\n\nAgenda \nOctober 12, 2021\nFinish bootstrapping\nQ & A\nOctober 14, 2021\nOffice hours during class\nExam some time on Thursday or Friday\nTake home due Sunday, October 24, 11:59pm\nReadings \nSample questions\nClicker questions\nReflection questions \nEach week’s reflection questions are given separately, see the Daily (read: weekly) pages.\nEthics considerations \nEach week’s ethics considerations are given separately, see the Daily (read: weekly) pages.\nSlides \nEach week’s slides are given separately, see the Daily (read: weekly) pages.\nAdditional Resources \nEach week’s warm-up exercises are given separately, see the Daily (read: weekly) pages.\n\n\n\n",
    "preview": "posts/2021-10-12-review1/../../images/reprex.png",
    "last_modified": "2022-01-15T18:36:53-08:00",
    "input_file": {},
    "preview_width": 3890,
    "preview_height": 2763
  },
  {
    "path": "posts/2021-10-05-bootstrap/",
    "title": "6. Bootstrapping",
    "description": "The sample as a proxy for the unknown population.  Sample from said proxy population (i.e., the sample) to generate a sampling distribution.  Bootstrap.",
    "author": [
      {
        "name": "Johanna Hardin",
        "url": "https://m154-comp-stats.netlify.app/"
      }
    ],
    "date": "2020-10-05",
    "categories": [],
    "contents": "\n\n\n\nFigure 1: Artwork by @allison_horst.\n\n\n\nAgenda \nOctober 5, 2021\nFinish power in the permutation test context\nReview: logic of confidence intervals\nLogic of bootstrapping (resample from the sample with replacement)\nBS SE of a statistic\nOctober 7, 2021\nNormal CI using BS SE\nBootstrap-t (studentized) CIs\nPercentile CIs\nproperties / advantages / disadvantages\nReadings \nClass notes: Bootstrapping\nBaumer, Horton, and Kaplan (2021), The bootstrap (Chp 9.3) in Modern Data Science for R.\nGareth, Witten, Hastie, and Tibshirani (2021), The Bootstrap (section 5.2)  Introduction to Statistical Learning.\nReflection questions \nWhy would anyone ever want to bootstrap?\nWhat are the differences between a normal CI with Boot SE, a Bootstrap-t CI, and a percentile interval?\nWhy do we need to bootstrap twice for the Bootstrap-t CI?\nWhat makes a confidence interval procedure good?\nEthics considerations \nWhy isn’t the bootstrap method a solution for the situation of small sample sizes?\nWhy isn’t the bootstrap method a solution for the situation with biased / unrepresentative data?\nConsider a population with a maximum value (the parameter of interest). Will the sample max have a sampling distribution which is centered on the true maximum? Why or why not? [Quintessential example of how a statistic can be biased for the parameter.]\nSlides \nIn class slides for both 10/5/21 and 10/7/21.\nWU10 - standard errors\nWU11 - Bootstrap SE\nAdditional Resources \nStatKey applets which demonstrate bootstrapping.\nConfidence interval logic from the Rossman & Chance applets.\nThe Role of Statistical Learning in Applied Statistics Daniela Witten talks to Rafa Irizarry June 15, 2020.\nFive ways to fix statistics, Nature Nov 28, 2017\n\n\n\n",
    "preview": "posts/2021-10-05-bootstrap/../../images/dotplot.png",
    "last_modified": "2022-01-15T18:36:44-08:00",
    "input_file": {},
    "preview_width": 887,
    "preview_height": 502
  }
]
