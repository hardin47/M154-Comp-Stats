---
title: "Bootstrapping"
author: "Jo Hardin"
date: "October 3 & 5, 2021"
output:
  xaringan::moon_reader:
    nature:
      highlightlines: true
      titleSlideClass: ["right", "top", "my-title"]
---

```{r include=FALSE}
library(tidyverse)
require(mosaic)
require(boot)
require(ggthemes)
require(knitr)
opts_chunk$set(
  message=FALSE,
  warning=FALSE,
  size='small',
  cache=TRUE,
  tidy=FALSE
  )
require(lubridate)
require(sysfonts)
options(width=65, digits=3)
```


## Why bootstrap?

Motivation:  

> to estimate the variability and distribution of a statistic in repeated samples of size $n$ (*not* dependent on $H_0$ being true).

---

## Variability

* standard deviation of the **data**: $s = \sqrt{\frac{X_i - \overline{X}}{n-1}}$

* standard error of the **statistic**: depends...

---

## Basic Notation

(n.b., we don't ever do what is on this slide)

Let $\theta$ be the parameter of interest, and let $\hat{\theta}$ be the estimate of $\theta$.  If we could, we'd take many samples of size $n$ from the population to create a **sampling distribution** for $\hat{\theta}$.  Consider taking $B$ random samples from the population.

\begin{align}
\hat{\theta}(\cdot) = \frac{1}{B} \sum_{i=1}^B \hat{\theta}_i
\end{align}
is the best guess for $\theta$.  If $\hat{\theta}$ is very different from $\theta$, we would call it **biased**.
\begin{align}
SE(\hat{\theta}) &= \bigg[ \frac{1}{B-1} \sum_{i=1}^B(\hat{\theta}_i - \hat{\theta}(\cdot))^2 \bigg]^{1/2}\\
q_1 &= [0.25 B] \ \ \ \ \hat{\theta}^{(q_1)} = \mbox{25}\% \mbox{ cutoff}\\
q_3 &= [0.75 B] \ \ \ \ \hat{\theta}^{(q_3)} = \mbox{75}\% \mbox{ cutoff}\\
\end{align}

---

## Ideally

(we never do this)

```{r out.width='100%', fig.align="center",  echo=FALSE, fig.cap = "From Hesterberg et al., Chapter 16 of Introduction to the Practice of Statistics by  Moore, McCabe, and Craig"}
knitr::include_graphics("../images/BSlogic.png")
```

---

## Bootstrap Procedure

1. Resample data **with replacement** from the original sample.
2. Calculate the statistic of interest for each resample.
3. Repeat 1. and 2. $B$ times.
4. Use the bootstrap distribution for inference.

---

## Bootstrap Notation

(n.b., bootstrapping is the process on this slide)

Take many ( $B$ ) resamples of size $n$ from the sample to create a bootstrap distribution for $\hat{\theta}^*$ (instead of the sampling distribution for $\hat{\theta}$).

Let $\hat{\theta}^*(b)$ be the calculated statistic of interest for the $b^{th}$ bootstrap sample.  The best guess for $\theta$ is:
\begin{align}
\hat{\theta}^* = \frac{1}{B} \sum_{b=1}^B \hat{\theta}^*(b)
\end{align}
(if $\hat{\theta}^*$ is very different from $\hat{\theta}$, we call it biased.)  And the estimated value for the standard error of the estimate is
\begin{align}
\hat{SE}^* = \bigg[ \frac{1}{B-1} \sum_{b=1}^B ( \hat{\theta}^*(b) - \hat{\theta}^*)^2 \bigg]^{1/2}
\end{align}

---

## What do we get?


Just like repeatedly taking samples from the population, taking resamples from the sample allows us to characterize the bootstrap distribution which approximates the sampling distribution.  The bootstrap distribution approximates the **shape, spread, & bias** of the actual sampling distribution.

---

```{r out.width='30%', fig.align="center",  echo=FALSE, fig.cap = "From Hesterberg et al., Chapter 16 of Introduction to the Practice of Statistics by  Moore, McCabe, and Craig.  The left image represents the mean with n=50.  The center image represents the mean with n=9.  The right image represents the median with n=15.", fig.show='hold'}
knitr::include_graphics(c("../images/BShesterberg1.png",
                          "../images/BShesterberg2.png",
                          "../images/BShesterberg3.png"))
```

---

## Example
- Hesketh and Everitt (2000) report on a study by Caplehorn and Bell (1991) that investigated the times that heroin addicts remained in a clinic for methadone maintenance treatment.  

- The data include the amount of time that the subjects stayed in the facility until treatment was terminated (column 4). 

- For about 37% of the subjects, the study ended while they were still the in clinic (status=0).  

- Their survival time has been truncated.  For this reason we might not want to estimate the mean survival time, but rather some other measure of typical survival time.  Below we explore using the median as well as the 25% trimmed mean.   (From ISCAM Chance & Rossman, Investigation 4.5.3)

---

## Reading in the data
```{r}
heroin <- readr::read_table2("http://www.rossmanchance.com/iscam2/data/heroin.txt")
heroin
```

---

## Observed Test Statistic(s)
```{r}
obs_med<-heroin %>% 
  summarize(medtime = median(times)) %>% pull()
obs_tr_mean<-heroin %>% 
  summarize(tmeantime = mean(times, trim=0.25)) %>% pull()

obs_med
obs_tr_mean
```

---


## Bootstrapped data!
```{r}
set.seed(4747)

heroin %>% sample_frac(size=1, replace=TRUE) %>%
  summarize(boot_med = median(times), boot_tr_mean = mean(times, trim = 0.25))

```

---


##  Need to bootstrap a lot of times...
Bootstrapping with `map`ping. 

```{r echo=FALSE}
n_rep1 <- 100
n_rep2 <- 20
set.seed(4747)
```

```{r}
boot_stat_func <- function(df = heroin){ 
	df %>% 
    sample_frac(size=1, replace=TRUE) %>%
    summarize(boot_med = median(times), boot_tr_mean = mean(times, trim = 0.25))}

boot_1_func <- function(df = heroin){
  df %>% 
    sample_frac(size=1, replace=TRUE)
}

boot_2_func <- function(df, reps){
  df %>%
    summarize(boot_med = median(times), boot_tr_mean = mean(times, trim = 0.25)) %>%
    cbind(map_df(1:reps, ~df %>% 
             sample_frac(size=1, replace=TRUE) %>%
             summarize(boot_2_med = median(times), 
                       boot_2_tr_mean = mean(times, trim = 0.25))))
}
```

```{r}
#n_rep1 <-5
#n_rep2 <- 3
results <- data.frame(set = 1:n_rep1) %>%
  mutate(first_boot = map(1:n_rep1, ~boot_1_func())) %>%
  mutate(second_boot = map(first_boot, boot_2_func, reps = n_rep2)) %>%
  unnest(second_boot) %>%
  unnest(first_boot)
```


---



## What do the **data** distributions look like?

```{r echo=FALSE, fig.width=4}
heroin %>% 
  ggplot(aes(x=times)) + 
  geom_histogram(bins=30) + 
  ggtitle("original sample")

heroin %>%
  boot_1_func() %>%
  ggplot(aes(x=times)) + 
  geom_histogram(bins=30) + 
  ggtitle("one bootstrap resample")
```


---

## What do the **sampling** distributions look like?

Both the median and the trimmed mean are symmetric and bell-shaped.  

.pull-left[
```{r echo=FALSE, fig.width=4, fig.height=6}
bs_stats <- map_df(1:n_rep1, ~boot_stat_func(), df = heroin)

ggplot(bs_stats, aes(x=boot_med)) + 
  geom_histogram(bins=20) + 
  ggtitle("dist of median") +  
  geom_vline(aes(xintercept = mean(boot_med))) 
  #xlab(paste("mean=",round(mean(boot_med),2),";
  #           SE=", round(sd(boot_med),2)))
```
]

.pull-right[
```{r echo=FALSE, fig.width=4, fig.height=6}
ggplot(bs_stats, aes(x=boot_tr_mean)) + 
  geom_histogram(bins=20) + 
  ggtitle("dist of trimmed mean") +  
  geom_vline(aes(xintercept = mean(boot_med))) 
  #xlab(paste("mean=",round(mean(boot_tr_mean),2),";
  #           SE=", round(sd(boot_tr_mean),2)))

```
]

```{r include = FALSE, eval = FALSE}
## OR using the built in functions
sampletmean <- function(x,d,trimperc){
  return(mean(x[d], trim=trimperc))
}
set.seed(4747)
bs.tmean.resamps <- boot(heroin$times,
                         sampletmean, reps1, trimperc=.25)
```

```{r include = FALSE, eval = FALSE}
## What does the boot output look like?
# bs.tmean.resamps <- boot(heroin$times,sampletmean, reps1, trimperc=.25)
str(bs.tmean.resamps)
```



```{r include = FALSE, eval = FALSE}
## What does the boot output look like?

samplemed <- function(x,d){
  return(median(x[d]))
}
set.seed(4747)
bs.med.resamps <- boot(heroin$times,
                       samplemed, reps1)
bs.med.resamps
```




```{r include = FALSE, eval = FALSE}
## SE of median
Whew!  They are very close (one using for loops, one using the boot function).


sd(test.stat)  # SE of median

bs.med.resamps
```



```{r include = FALSE, eval = FALSE}
## SE of trimmed mean

Whew!  They are very close (one using for loops, one using the boot function).

sd(test.stat2)  # SE of trimmed mean

bs.tmean.resamps
```

---

## 95% normal CI with BS SE

.pull-left[
Without built in functions
```{r include = FALSE, eval = FALSE}
bs_stats + 
  qnorm(c(.025,.975))*
  sd(test.stat)
obs.stat2 + 
  qnorm(c(.025,.975))*
  sd(test.stat2)
```
]

.pull-right[
```{r include = FALSE, eval = FALSE}
With built in functions
se.bs <- sd(bs.med.resamps$t)
se.bs2 <- sd(bs.tmean.resamps$t)

obs.stat + 
  qnorm(c(0.025,.975))*
  se.bs

obs.stat2 + 
  qnorm(c(0.025,.975))*
  se.bs2 
```
]

---


## 95% Percentile CI

.pull-left[
Without built in functions
```{r include = FALSE, eval = FALSE}
quantile(test.stat, c(.025, .975))
quantile(test.stat2, c(.025, .975))
```
]

.pull-right[
```{r include = FALSE, eval = FALSE}
With built in functions
quantile(bs.med.resamps$t, c(.025, .975))
quantile(bs.tmean.resamps$t, c(.025, .975))
```
]

```{r include = FALSE, eval = FALSE}
### With built in functions more directly
boot.ci(bs.med.resamps, type="perc")
boot.ci(bs.tmean.resamps, type="perc")
```

---

## 95% Bootstrap-t CI


Note that the t-value is needed (which requires a different SE for each bootstrap sample).

```{r include = FALSE, eval = FALSE}
t.hat<-(test.stat - obs.stat)/sd.test.stat
t.hat2<-(test.stat2 - obs.stat2)/sd.test.stat2

t.hat.95 = quantile(t.hat, c(.025,.975))
t.hat2.95 = quantile(t.hat2, c(.025,.975))

obs.stat + t.hat.95*sd(test.stat)

obs.stat2 + t.hat2.95*sd(test.stat2) 
```


```{r include = FALSE, eval = FALSE}
### With built in functions

Trimmed mean:

  
sampletmean2 <- function(x, d, R2, trimperc) {
   boot.samp = x[d]  # boostrapped sample
   m.bs = mean(boot.samp, trim=trimperc)  # bootstrapped mean
   v.bs = var(boot(boot.samp, sampletmean, R2, trim=trimperc)$t)
   return(c(m.bs, v.bs))  
   # boot expects the statistic to be the 1st and the var to be the 2nd
}
set.seed(4747)
bs.tmean.reresamps <- boot(heroin$times, sampletmean2, R=reps1, R2=reps2, trimperc=.25)
```


```{r include = FALSE, eval = FALSE}
### With built in functions

Median:

  
samplemed2 <- function(x, d, R2) {
   boot.samp = x[d]  # boostrapped sample
   m.bs = median(boot.samp)  # bootstrapped mean
   v.bs = var(boot(boot.samp, samplemed, R2)$t)
   return(c(m.bs, v.bs))  
   # boot expects the statistic to be the 1st and the var to be the 2nd
}
set.seed(4747)
bs.med.reresamps <- boot(heroin$times, samplemed2, R=reps1, R2=reps2)
```


```{r include = FALSE, eval = FALSE}
The confidence intervals (BS-t intervals, called "studentized"):

  boot.ci(bs.med.reresamps, type="stud")
boot.ci(bs.tmean.reresamps, type="stud")
```

---

## 95% BCa interval (not responsible for BCa)

```{r include = FALSE, eval = FALSE}
### With built in functions

boot.ci(bs.med.reresamps, type="bca")
boot.ci(bs.tmean.reresamps, type="bca")
```


### Without built in functions
```{r include = FALSE, eval = FALSE}
test.stat.jk<-c()
test.stat2.jk<-c()

set.seed(4747)
for(i in 1:length(heroin$times)){

	test.stat.jk<-c(test.stat.jk,median(heroin$times[-i]))
	 test.stat2.jk<-c(test.stat2.jk,mean(heroin$times[-i],trim=.25))
}

zo.hat<-qnorm(sum(test.stat<obs.stat)/reps1,0,1)
a.hat<- sum((mean(test.stat.jk) - test.stat.jk)^3)/
                 (6*(sum((mean(test.stat.jk)-test.stat.jk)^2)^1.5))

zo.hat2<- qnorm(sum(test.stat2< obs.stat2)/reps1,0,1)
a.hat2<- sum((mean(test.stat2.jk) - test.stat2.jk)^3)/
                 (6*(sum((mean(test.stat2.jk)-test.stat2.jk)^2)^1.5))

alpha1.bca<-pnorm(zo.hat + (zo.hat + qnorm(.975))/(1 - a.hat*(zo.hat + qnorm(.975))))
alpha2.bca<-pnorm(zo.hat + (zo.hat + qnorm(.025))/(1 - a.hat*(zo.hat + qnorm(.025))))


alpha1.bca2<-pnorm(zo.hat2 + (zo.hat2 + qnorm(.975))/(1 - a.hat2*(zo.hat2 + qnorm(.975))))
alpha2.bca2<-pnorm(zo.hat2 + (zo.hat2 + qnorm(.025))/(1 - a.hat2*(zo.hat2 + qnorm(.025))))


c(sort(test.stat)[ceiling(reps1*alpha2.bca)],sort(test.stat)[ceiling(reps1*alpha1.bca)])
c(sort(test.stat2)[ceiling(reps1*alpha2.bca2)],sort(test.stat2)[ceiling(reps1*alpha1.bca2)])
```

---

## Comparison of intervals

The first three columns  correspond to the CIs for the true median of the survival times.  The second three columns correspond to the CIs for the true trimmed mean of the survival times.


CI | lower | observed | upper | lower | observed | upper
--- | ----- | ----- | ----- | ----- | ------ | -------- | 
Percentile | 321.00 | 367.50| 452.00 | 339.38 | 378.30 | 423.46
CI w BS SE | 306.33 | 367.50|428.67 | 335.21 | 378.30 | 421.39
BS-t | 294.98 | 367.50|418.00 | 334.28 | 378.30 | 418.09
BCa | 317.00 | 367.50|444.00 | 338.29 | 378.30 | 422.43







